{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of the self-calibration pipeline on an ETH3D SLAM dataset.  \n",
        "Given only a sequence of RGB images from a single moving camera, it:\n",
        "\n",
        "1. Downloads and loads a monocular ETH3D sequence.\n",
        "2. Detects and matches local features between frames.\n",
        "3. Selects geometrically consistent frame pairs and estimates their Fundamental matrices (F).\n",
        "4. Recovers an initial camera intrinsic matrix (K) (focal length and principal point) from epipolar geometry.\n",
        "5. Initializes camera poses and triangulates an initial set of 3D points.\n",
        "6. Incrementally extends the reconstruction across many frames using PnP + triangulation.\n",
        "7. Performs global reprojection-based outlier filtering.\n",
        "8. Refines focal length and principal point with a small-scale bundle-adjustment-like (BA) optimization.\n",
        "9. Saves the estimated intrinsics, camera poses, and 3D points, and optionally compares them against ground truth."
      ],
      "metadata": {
        "id": "yZPkZ_v_Gld4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LxgwdWnEM0PD"
      },
      "outputs": [],
      "source": [
        "!pip -q install opencv-python-headless==4.10.0.84 numpy scipy\n",
        "\n",
        "import os, sys, glob, json, shutil, zipfile, pathlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a monocular sequence from the ETH3D SLAM dataset\n",
        "import urllib.request, os, zipfile\n",
        "\n",
        "root = \"/content/eth3d\"\n",
        "os.makedirs(root, exist_ok=True)\n",
        "name = \"einstein_1\"   # dataset's name\n",
        "mono_url = f\"https://www.eth3d.net/data/slam/datasets/{name}_mono.zip\"\n",
        "dst_zip  = f\"{root}/{name}_mono.zip\"\n",
        "dst_dir  = f\"{root}/training\"\n",
        "\n",
        "os.makedirs(dst_dir, exist_ok=True)\n",
        "print(\"Downloading:\", mono_url)\n",
        "urllib.request.urlretrieve(mono_url, dst_zip)\n",
        "\n",
        "with zipfile.ZipFile(dst_zip, 'r') as z:\n",
        "    z.extractall(dst_dir)\n",
        "os.remove(dst_zip)\n",
        "\n",
        "# Locate folder with RGB images\n",
        "rgb_dir = glob.glob(f\"{dst_dir}/{name}/**/rgb\", recursive=True)[0]\n",
        "print(\"Images dir:\", rgb_dir, \"num imgs:\", len(glob.glob(rgb_dir+'/*.png')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvkIpTYcRjKK",
        "outputId": "d4bd7657-0a49-45a6-8d85-4c8f0b3ecfec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: https://www.eth3d.net/data/slam/datasets/einstein_1_mono.zip\n",
            "Images dir: /content/eth3d/training/einstein_1/rgb num imgs: 487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all PNG images from the RGB directory of ETH3D format\n",
        "img_paths = sorted(glob.glob(os.path.join(rgb_dir, \"*.png\")))\n",
        "assert len(img_paths) > 0, f\"No PNGs in {rgb_dir}\"\n",
        "images = [cv2.imread(p, cv2.IMREAD_COLOR) for p in img_paths]\n",
        "assert all(im is not None for im in images), \"Some images failed to load\"\n",
        "\n",
        "# Extract image dimensions\n",
        "H, W = images[0].shape[:2]\n",
        "print(f\"Loaded {len(images)} frames, HxW={H}x{W}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHPURKBsT3LT",
        "outputId": "1df86768-5d9e-41cc-ee3c-291c137ef56e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 487 frames, HxW=458x739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define control parameters for speed/robustness\n",
        "STRIDE     = 2      # Downsample frame sequence by this stride\n",
        "MAX_FRAMES = 150    # Limit total number of frames\n",
        "TARGET_W   = 1280   # Rescale width (used for feature extraction)\n",
        "FEATURE    = \"sift\" # Feature type: \"sift\" | \"orb\"\n",
        "\n",
        "# Apply frame stride and limit number of frames\n",
        "images = images[::STRIDE][:MAX_FRAMES]\n",
        "H, W = images[0].shape[:2]\n",
        "cx, cy = W * 0.5, H * 0.5 # Principal point is assumed to be the image center\n",
        "print(f\"Using {len(images)} frames after stride, HxW={H}x{W}\")\n",
        "\n",
        "# Initialize intrinsic matrix K\n",
        "f0 = 1.2 * max(H, W)\n",
        "fx = float(f0)\n",
        "fy = float(f0)\n",
        "K = np.array([[fx, 0.0, cx],\n",
        "              [0.0, fy,  cy],\n",
        "              [0.0, 0.0, 1.0]], dtype=np.float64)\n",
        "\n",
        "# Store intrinsic priors (used later for regularization in Bundle Adjustment)\n",
        "K_prior = (fx, fy, cx, cy)\n",
        "\n",
        "\n",
        "# Data container for storing keypoints and descriptors per frame\n",
        "@dataclass\n",
        "class FrameData:\n",
        "    kps: List[cv2.KeyPoint] # List of keypoints detected in the image\n",
        "    desc: np.ndarray        # Corresponding descriptor matrix\n",
        "    pts_px: np.ndarray      # Pixel coordinates (N x 2) at original resolution\n",
        "\n",
        "# Create a feature extractor\n",
        "def create_feature(name=\"sift\"):\n",
        "    name = (name or \"sift\").lower()\n",
        "    if name == \"sift\":\n",
        "        try:\n",
        "            return cv2.SIFT_create(nfeatures=3000)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return cv2.ORB_create(nfeatures=3000, scaleFactor=1.2, nlevels=10, edgeThreshold=15, fastThreshold=7)\n",
        "\n",
        "# Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance image contrast\n",
        "def preprocess_gray(g):\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    return clahe.apply(g)\n",
        "\n",
        "# Convert an image to grayscale\n",
        "def to_gray(img):\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim==3 else img\n",
        "\n",
        "def match_descriptors(d1, d2, ratio=0.80, min_matches=50):\n",
        "    \"\"\"\n",
        "    Perform two-way descriptor matching:\n",
        "    - Forward: KNN + Lowe's ratio test.\n",
        "    - Reverse: 1-NN verification to ensure mutual correspondence.\n",
        "    Returns a list of matches that satisfy both filters.\n",
        "    \"\"\"\n",
        "    # Sanity checks to ensure both descriptor sets are non-empty\n",
        "    if d1 is None or d2 is None:\n",
        "        return []\n",
        "    if len(d1) == 0 or len(d2) == 0:\n",
        "        return []\n",
        "\n",
        "    # Choose matcher type based on descriptor data type\n",
        "    is_bin = (d1.dtype == np.uint8 and d2.dtype == np.uint8)\n",
        "    if is_bin:\n",
        "        matcher_fwd = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "        matcher_rev = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "        d1_use, d2_use = d1, d2\n",
        "        d2_use_rev, d1_use_rev = d2, d1\n",
        "    else:\n",
        "        d1_use = np.asarray(d1, dtype=np.float32)\n",
        "        d2_use = np.asarray(d2, dtype=np.float32)\n",
        "        d2_use_rev = d2_use\n",
        "        d1_use_rev = d1_use\n",
        "        index_params = dict(algorithm=1, trees=5)\n",
        "        search_params = dict(checks=64)\n",
        "        matcher_fwd = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "        matcher_rev = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Perform KNN matching (k=2) for Lowe's ratio filtering\n",
        "    knn = matcher_fwd.knnMatch(d1_use, d2_use, k=2)\n",
        "    ratio_pass = []\n",
        "    for pair in knn:\n",
        "        if len(pair) < 2:\n",
        "            continue\n",
        "        m, n = pair\n",
        "        if m.distance < ratio * n.distance:\n",
        "            ratio_pass.append(m)\n",
        "\n",
        "    if not ratio_pass:\n",
        "        return []\n",
        "\n",
        "    # Perform reverse 1-NN matching to check mutual correspondence\n",
        "    knn_rev = matcher_rev.knnMatch(d2_use_rev, d1_use_rev, k=1)\n",
        "    rev_map = {}\n",
        "    for pair in knn_rev:\n",
        "        if not pair:\n",
        "            continue\n",
        "        r = pair[0]\n",
        "        rev_map[r.queryIdx] = r.trainIdx\n",
        "\n",
        "    # Mutual match check: only retain matches where forward and reverse agree\n",
        "    mutual = []\n",
        "    seen = set()  # avoid duplicates\n",
        "    for m in ratio_pass:\n",
        "        if rev_map.get(m.trainIdx, -1) == m.queryIdx:\n",
        "            key = (m.queryIdx, m.trainIdx)\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                mutual.append(m)\n",
        "\n",
        "    # If mutual matches are too few, skip further processing\n",
        "    if len(mutual) < min_matches:\n",
        "        return []\n",
        "\n",
        "    return mutual\n",
        "\n",
        "# Robust estimation of the Fundamental matrix\n",
        "def ransac_F(pts1, pts2):\n",
        "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n",
        "                                     ransacReprojThreshold=3.0, confidence=0.995, maxIters=4000)\n",
        "    # Retry with more iterations if initial estimation fails\n",
        "    if F is None or F.shape!=(3,3):\n",
        "        F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n",
        "                                         ransacReprojThreshold=3.0, confidence=0.995, maxIters=8000)\n",
        "    mask = (mask.ravel().astype(bool) if mask is not None else np.zeros(len(pts1), bool))\n",
        "    return F, mask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmdluZ-2W5lx",
        "outputId": "11480eaf-cd0d-4eca-b587-1fd1c0799b7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 150 frames after stride, HxW=458x739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat = create_feature(FEATURE)\n",
        "\n",
        "# Initialize the list to store extracted feature information for each frame\n",
        "frames: List[FrameData] = []\n",
        "\n",
        "for img in images:\n",
        "    # Compute the scaling factor to resize the image to the target working width\n",
        "    scale = min(1.0, TARGET_W / float(img.shape[1]))\n",
        "    img_small = cv2.resize(img, (int(img.shape[1]*scale), int(img.shape[0]*scale)),\n",
        "                           interpolation=cv2.INTER_AREA) if scale<1.0 else img\n",
        "    gray = preprocess_gray(to_gray(img_small))\n",
        "\n",
        "    # Detect keypoints and compute descriptors using the selected feature detector\n",
        "    kps_small, desc = feat.detectAndCompute(gray, None)\n",
        "\n",
        "    # Map keypoints back to original scale so the rest of geometry uses full-res pixels\n",
        "    kps, pts_px = [], []\n",
        "    inv = 1.0 / scale\n",
        "\n",
        "    if scale == 1.0:\n",
        "        # No scaling was applied\n",
        "        kps = kps_small\n",
        "        pts_px = [kp.pt for kp in kps_small]\n",
        "    else:\n",
        "        for kp in kps_small:\n",
        "            x = kp.pt[0] * inv\n",
        "            y = kp.pt[1] * inv\n",
        "\n",
        "            # Scale the keypoint size appropriately and preserve its original attributes\n",
        "            size   = max(1.0, kp.size * inv)\n",
        "            angle  = float(kp.angle) if kp.angle is not None else -1.0\n",
        "            resp   = float(kp.response)\n",
        "            octave = int(kp.octave)\n",
        "            clsid  = int(kp.class_id)\n",
        "\n",
        "            new_kp = cv2.KeyPoint(float(x), float(y), float(size), float(angle), resp, octave, clsid)\n",
        "\n",
        "            # Append the new keypoint and its position to the lists\n",
        "            kps.append(new_kp)\n",
        "            pts_px.append([x, y])\n",
        "\n",
        "    pts_px = np.array(pts_px, dtype=np.float32)\n",
        "    frames.append(FrameData(kps=kps, desc=desc, pts_px=pts_px))\n",
        "\n",
        "\n",
        "print(\"Features extracted for\", len(frames), \"frames\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlXwlA-bW-Ni",
        "outputId": "a6d9f626-4f3d-4fe3-f039-0d90efc62e13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features extracted for 150 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel coordinates using camera intrinsics\n",
        "def normalize_points(pts_px, K):\n",
        "    fx, fy = K[0,0], K[1,1]; cx, cy = K[0,2], K[1,2]\n",
        "    x = (pts_px[:,0]-cx)/fx; y = (pts_px[:,1]-cy)/fy\n",
        "    return np.stack([x,y], axis=1)"
      ],
      "metadata": {
        "id": "5s44RFC07EUh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store high-quality image pairs with sufficient parallax and valid epipolar geometry\n",
        "good_pairs = []\n",
        "\n",
        "# Helper function to skip visually similar consecutive frames\n",
        "def frames_too_similar(i, j, thr=1.5):\n",
        "    g1 = to_gray(images[i]).astype(np.float32)\n",
        "    g2 = to_gray(images[j]).astype(np.float32)\n",
        "    return float(np.mean(np.abs(g1 - g2))) < thr\n",
        "\n",
        "# Main loop to iterate over the frame sequence and identify geometrically valid pairs\n",
        "i = 0\n",
        "while i < len(frames)-1:\n",
        "    tried = False\n",
        "\n",
        "    # Try pairing current frame with the next or the one after\n",
        "    for j in (i+1, i+2 if i+2 < len(frames) else i+1):\n",
        "        if j >= len(frames) or frames_too_similar(i,j):\n",
        "            continue\n",
        "        f1, f2 = frames[i], frames[j]\n",
        "\n",
        "        # Match descriptors with Lowe's ratio test + mutual check\n",
        "        matches = match_descriptors(f1.desc, f2.desc, ratio=0.85)\n",
        "        if len(matches) < 60:\n",
        "            continue\n",
        "\n",
        "        # Extract matched keypoint coordinates\n",
        "        pts1 = np.array([f1.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "        pts2 = np.array([f2.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "        F, mask = ransac_F(pts1, pts2)\n",
        "        inl = int(mask.sum())\n",
        "\n",
        "        print(f\"[debug] {i}-{j} matches = {len(matches)}\")\n",
        "        if F is not None:\n",
        "            print(f\"[debug]     inliers = {inl}, cond(F) = {np.linalg.cond(F):.1e}\")\n",
        "\n",
        "        # Check quality of fundamental matrix and number of inliers\n",
        "        if F is not None and inl >= 30 and np.linalg.cond(F) < 1e20:\n",
        "            good = [matches[k] for k in range(len(matches)) if mask[k]]\n",
        "            x1n = normalize_points(pts1[mask], K)\n",
        "            x2n = normalize_points(pts2[mask], K)\n",
        "\n",
        "            # Estimate relative pose using the essential matrix derived from F\n",
        "            E_tmp = K.T @ F @ K\n",
        "            _, Rtmp, ttmp, _ = cv2.recoverPose(\n",
        "                E_tmp,\n",
        "                cv2.undistortPoints(pts1[mask].reshape(-1,1,2), K, None),\n",
        "                cv2.undistortPoints(pts2[mask].reshape(-1,1,2), K, None)\n",
        "            )\n",
        "\n",
        "            # Create normalized ray directions for both views\n",
        "            b1 = np.column_stack([x1n, np.ones(len(x1n))])\n",
        "            b2 = (Rtmp @ np.column_stack([x2n, np.ones(len(x2n))]).T).T\n",
        "            b1 /= np.linalg.norm(b1, axis=1, keepdims=True)\n",
        "            b2 /= np.linalg.norm(b2, axis=1, keepdims=True)\n",
        "\n",
        "            # Compute parallax angles (in degrees) between rays\n",
        "            ang = np.degrees(np.arccos(np.clip(np.sum(b1*b2, axis=1), -1, 1)))\n",
        "\n",
        "            if np.median(ang) < 1.5:\n",
        "                continue\n",
        "\n",
        "            good_pairs.append((i, j, good, F))\n",
        "            i = j\n",
        "            tried = True\n",
        "            break\n",
        "\n",
        "    if not tried:\n",
        "        print(f\"[warn] Skipping weak pair at {i}-{i+1}\")\n",
        "        i += 1\n",
        "    #if len(good_pairs) >= 60:\n",
        "    #    print(f\"[info] Enough good pairs: {len(good_pairs)}. Stop.\")\n",
        "    #    break\n",
        "\n",
        "assert len(good_pairs) > 0, \"No good pairs found. Try larger STRIDE or different sequence.\"\n",
        "print(\"Good pairs:\", len(good_pairs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARMGLwx6YvUM",
        "outputId": "8ac80bbd-1f18-4ccd-e0c0-2a25731b942d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] 0-1 matches = 118\n",
            "[debug]     inliers = 108, cond(F) = 8.7e+16\n",
            "[debug] 1-2 matches = 116\n",
            "[debug]     inliers = 107, cond(F) = 7.7e+16\n",
            "[debug] 2-3 matches = 128\n",
            "[debug]     inliers = 115, cond(F) = 2.5e+16\n",
            "[debug] 3-4 matches = 162\n",
            "[debug]     inliers = 153, cond(F) = 7.9e+17\n",
            "[debug] 4-5 matches = 154\n",
            "[debug]     inliers = 144, cond(F) = inf\n",
            "[debug] 4-6 matches = 143\n",
            "[debug]     inliers = 130, cond(F) = 1.4e+17\n",
            "[debug] 6-7 matches = 185\n",
            "[debug]     inliers = 176, cond(F) = 5.8e+16\n",
            "[debug] 6-8 matches = 169\n",
            "[debug]     inliers = 158, cond(F) = 3.7e+17\n",
            "[debug] 8-9 matches = 191\n",
            "[debug]     inliers = 176, cond(F) = 5.5e+16\n",
            "[debug] 8-10 matches = 184\n",
            "[debug]     inliers = 167, cond(F) = 2.1e+17\n",
            "[debug] 10-11 matches = 199\n",
            "[debug]     inliers = 193, cond(F) = 1.0e+17\n",
            "[debug] 11-12 matches = 202\n",
            "[debug]     inliers = 190, cond(F) = 2.6e+17\n",
            "[debug] 11-13 matches = 185\n",
            "[debug]     inliers = 175, cond(F) = 1.8e+17\n",
            "[debug] 13-14 matches = 229\n",
            "[debug]     inliers = 223, cond(F) = 7.5e+17\n",
            "[debug] 13-15 matches = 224\n",
            "[debug]     inliers = 210, cond(F) = 5.2e+17\n",
            "[warn] Skipping weak pair at 13-14\n",
            "[debug] 14-15 matches = 247\n",
            "[debug]     inliers = 233, cond(F) = 1.3e+17\n",
            "[debug] 14-16 matches = 251\n",
            "[debug]     inliers = 235, cond(F) = 3.1e+17\n",
            "[debug] 16-17 matches = 280\n",
            "[debug]     inliers = 270, cond(F) = 1.9e+16\n",
            "[debug] 16-18 matches = 238\n",
            "[debug]     inliers = 219, cond(F) = 3.8e+17\n",
            "[debug] 18-19 matches = 246\n",
            "[debug]     inliers = 228, cond(F) = 1.3e+17\n",
            "[debug] 18-20 matches = 210\n",
            "[debug]     inliers = 182, cond(F) = 5.7e+18\n",
            "[debug] 20-21 matches = 227\n",
            "[debug]     inliers = 208, cond(F) = 2.0e+16\n",
            "[debug] 21-22 matches = 251\n",
            "[debug]     inliers = 233, cond(F) = 5.7e+17\n",
            "[debug] 22-23 matches = 306\n",
            "[debug]     inliers = 279, cond(F) = 7.2e+16\n",
            "[debug] 22-24 matches = 285\n",
            "[debug]     inliers = 263, cond(F) = 9.7e+16\n",
            "[debug] 24-25 matches = 339\n",
            "[debug]     inliers = 324, cond(F) = 8.8e+16\n",
            "[debug] 24-26 matches = 260\n",
            "[debug]     inliers = 240, cond(F) = 1.1e+18\n",
            "[debug] 26-27 matches = 273\n",
            "[debug]     inliers = 252, cond(F) = 1.2e+17\n",
            "[debug] 27-28 matches = 299\n",
            "[debug]     inliers = 290, cond(F) = 5.0e+16\n",
            "[debug] 27-29 matches = 263\n",
            "[debug]     inliers = 244, cond(F) = 5.3e+16\n",
            "[debug] 29-30 matches = 362\n",
            "[debug]     inliers = 341, cond(F) = 1.3e+17\n",
            "[debug] 29-31 matches = 301\n",
            "[debug]     inliers = 258, cond(F) = 2.0e+17\n",
            "[debug] 31-32 matches = 278\n",
            "[debug]     inliers = 251, cond(F) = 2.8e+16\n",
            "[debug] 32-33 matches = 210\n",
            "[debug]     inliers = 191, cond(F) = 7.5e+16\n",
            "[debug] 33-34 matches = 236\n",
            "[debug]     inliers = 224, cond(F) = 2.2e+18\n",
            "[debug] 34-35 matches = 260\n",
            "[debug]     inliers = 241, cond(F) = 2.2e+16\n",
            "[debug] 35-36 matches = 280\n",
            "[debug]     inliers = 268, cond(F) = 6.4e+16\n",
            "[debug] 36-37 matches = 294\n",
            "[debug]     inliers = 277, cond(F) = 3.9e+16\n",
            "[debug] 36-38 matches = 289\n",
            "[debug]     inliers = 251, cond(F) = 7.6e+16\n",
            "[warn] Skipping weak pair at 36-37\n",
            "[debug] 37-38 matches = 419\n",
            "[debug]     inliers = 395, cond(F) = 3.5e+16\n",
            "[debug] 37-39 matches = 389\n",
            "[debug]     inliers = 347, cond(F) = 1.2e+18\n",
            "[warn] Skipping weak pair at 37-38\n",
            "[debug] 38-39 matches = 432\n",
            "[debug]     inliers = 417, cond(F) = 1.2e+17\n",
            "[debug] 38-40 matches = 386\n",
            "[debug]     inliers = 355, cond(F) = 4.4e+17\n",
            "[warn] Skipping weak pair at 38-39\n",
            "[debug] 39-40 matches = 428\n",
            "[debug]     inliers = 391, cond(F) = 2.7e+16\n",
            "[debug] 39-41 matches = 414\n",
            "[debug]     inliers = 345, cond(F) = 1.9e+19\n",
            "[warn] Skipping weak pair at 39-40\n",
            "[debug] 40-41 matches = 448\n",
            "[debug]     inliers = 428, cond(F) = 3.4e+17\n",
            "[debug] 41-42 matches = 340\n",
            "[debug]     inliers = 324, cond(F) = 8.0e+17\n",
            "[debug] 42-43 matches = 299\n",
            "[debug]     inliers = 281, cond(F) = 1.3e+17\n",
            "[debug] 43-44 matches = 281\n",
            "[debug]     inliers = 264, cond(F) = 3.0e+17\n",
            "[debug] 44-45 matches = 473\n",
            "[debug]     inliers = 446, cond(F) = 3.9e+17\n",
            "[debug] 44-46 matches = 408\n",
            "[debug]     inliers = 372, cond(F) = 9.0e+16\n",
            "[warn] Skipping weak pair at 44-45\n",
            "[debug] 45-46 matches = 429\n",
            "[debug]     inliers = 411, cond(F) = 2.1e+17\n",
            "[debug] 45-47 matches = 440\n",
            "[debug]     inliers = 398, cond(F) = 2.0e+17\n",
            "[debug] 47-48 matches = 497\n",
            "[debug]     inliers = 471, cond(F) = 1.2e+16\n",
            "[debug] 47-49 matches = 484\n",
            "[debug]     inliers = 436, cond(F) = 1.1e+16\n",
            "[debug] 49-50 matches = 535\n",
            "[debug]     inliers = 504, cond(F) = 8.9e+16\n",
            "[debug] 49-51 matches = 491\n",
            "[debug]     inliers = 446, cond(F) = 1.8e+18\n",
            "[debug] 51-52 matches = 467\n",
            "[debug]     inliers = 449, cond(F) = 3.6e+16\n",
            "[debug] 51-53 matches = 422\n",
            "[debug]     inliers = 371, cond(F) = 1.6e+17\n",
            "[debug] 53-54 matches = 448\n",
            "[debug]     inliers = 407, cond(F) = 1.0e+17\n",
            "[debug] 53-55 matches = 444\n",
            "[debug]     inliers = 385, cond(F) = 1.6e+18\n",
            "[debug] 55-56 matches = 385\n",
            "[debug]     inliers = 355, cond(F) = 2.1e+17\n",
            "[debug] 55-57 matches = 465\n",
            "[debug]     inliers = 407, cond(F) = 8.0e+17\n",
            "[warn] Skipping weak pair at 55-56\n",
            "[debug] 56-57 matches = 361\n",
            "[debug]     inliers = 334, cond(F) = 2.4e+16\n",
            "[debug] 57-58 matches = 518\n",
            "[debug]     inliers = 488, cond(F) = 3.3e+16\n",
            "[debug] 57-59 matches = 465\n",
            "[debug]     inliers = 416, cond(F) = 2.4e+17\n",
            "[debug] 59-60 matches = 506\n",
            "[debug]     inliers = 465, cond(F) = 5.0e+17\n",
            "[debug] 59-61 matches = 358\n",
            "[debug]     inliers = 288, cond(F) = 4.3e+17\n",
            "[warn] Skipping weak pair at 59-60\n",
            "[debug] 60-61 matches = 373\n",
            "[debug]     inliers = 333, cond(F) = 1.4e+16\n",
            "[debug] 61-62 matches = 358\n",
            "[debug]     inliers = 318, cond(F) = 4.0e+17\n",
            "[debug] 61-63 matches = 323\n",
            "[debug]     inliers = 264, cond(F) = 6.7e+16\n",
            "[debug] 63-64 matches = 494\n",
            "[debug]     inliers = 463, cond(F) = 7.9e+16\n",
            "[debug] 63-65 matches = 379\n",
            "[debug]     inliers = 339, cond(F) = 4.9e+19\n",
            "[debug] 65-66 matches = 448\n",
            "[debug]     inliers = 427, cond(F) = 5.0e+16\n",
            "[debug] 65-67 matches = 383\n",
            "[debug]     inliers = 355, cond(F) = 2.8e+17\n",
            "[debug] 67-68 matches = 432\n",
            "[debug]     inliers = 403, cond(F) = 5.9e+16\n",
            "[debug] 67-69 matches = 411\n",
            "[debug]     inliers = 382, cond(F) = 8.3e+16\n",
            "[debug] 69-70 matches = 543\n",
            "[debug]     inliers = 472, cond(F) = 3.5e+17\n",
            "[debug] 69-71 matches = 418\n",
            "[debug]     inliers = 396, cond(F) = 1.3e+17\n",
            "[warn] Skipping weak pair at 69-70\n",
            "[debug] 70-71 matches = 457\n",
            "[debug]     inliers = 421, cond(F) = 9.6e+16\n",
            "[debug] 71-72 matches = 467\n",
            "[debug]     inliers = 424, cond(F) = 1.0e+17\n",
            "[debug] 71-73 matches = 363\n",
            "[debug]     inliers = 293, cond(F) = inf\n",
            "[warn] Skipping weak pair at 71-72\n",
            "[debug] 72-73 matches = 355\n",
            "[debug]     inliers = 309, cond(F) = 6.5e+16\n",
            "[debug] 72-74 matches = 335\n",
            "[debug]     inliers = 294, cond(F) = 6.1e+17\n",
            "[debug] 74-75 matches = 370\n",
            "[debug]     inliers = 329, cond(F) = 1.1e+17\n",
            "[debug] 75-76 matches = 498\n",
            "[debug]     inliers = 457, cond(F) = 2.8e+19\n",
            "[debug] 75-77 matches = 419\n",
            "[debug]     inliers = 373, cond(F) = 7.4e+17\n",
            "[debug] 77-78 matches = 492\n",
            "[debug]     inliers = 437, cond(F) = 5.0e+16\n",
            "[debug] 77-79 matches = 467\n",
            "[debug]     inliers = 426, cond(F) = 1.2e+19\n",
            "[debug] 79-80 matches = 483\n",
            "[debug]     inliers = 435, cond(F) = 3.1e+17\n",
            "[debug] 80-81 matches = 501\n",
            "[debug]     inliers = 435, cond(F) = 2.4e+17\n",
            "[debug] 80-82 matches = 418\n",
            "[debug]     inliers = 336, cond(F) = 2.9e+17\n",
            "[debug] 82-83 matches = 558\n",
            "[debug]     inliers = 505, cond(F) = 5.3e+17\n",
            "[debug] 83-84 matches = 623\n",
            "[debug]     inliers = 586, cond(F) = 3.1e+16\n",
            "[debug] 84-85 matches = 615\n",
            "[debug]     inliers = 575, cond(F) = 1.3e+17\n",
            "[debug] 85-86 matches = 551\n",
            "[debug]     inliers = 490, cond(F) = 6.4e+18\n",
            "[debug] 85-87 matches = 579\n",
            "[debug]     inliers = 516, cond(F) = 5.9e+16\n",
            "[debug] 87-88 matches = 497\n",
            "[debug]     inliers = 451, cond(F) = 6.4e+17\n",
            "[debug] 87-89 matches = 311\n",
            "[debug]     inliers = 256, cond(F) = 4.4e+17\n",
            "[debug] 89-90 matches = 340\n",
            "[debug]     inliers = 301, cond(F) = 5.3e+16\n",
            "[debug] 90-91 matches = 513\n",
            "[debug]     inliers = 466, cond(F) = 4.5e+16\n",
            "[debug] 90-92 matches = 499\n",
            "[debug]     inliers = 399, cond(F) = 2.6e+19\n",
            "[debug] 92-93 matches = 390\n",
            "[debug]     inliers = 332, cond(F) = 1.1e+17\n",
            "[debug] 93-94 matches = 399\n",
            "[debug]     inliers = 373, cond(F) = 2.1e+18\n",
            "[debug] 94-95 matches = 380\n",
            "[debug]     inliers = 306, cond(F) = 1.3e+17\n",
            "[debug] 95-96 matches = 584\n",
            "[debug]     inliers = 517, cond(F) = 1.2e+17\n",
            "[debug] 96-97 matches = 496\n",
            "[debug]     inliers = 466, cond(F) = 2.7e+17\n",
            "[debug] 96-98 matches = 478\n",
            "[debug]     inliers = 416, cond(F) = 3.0e+16\n",
            "[debug] 98-99 matches = 488\n",
            "[debug]     inliers = 430, cond(F) = 7.1e+16\n",
            "[debug] 98-100 matches = 405\n",
            "[debug]     inliers = 337, cond(F) = 1.3e+18\n",
            "[debug] 100-101 matches = 537\n",
            "[debug]     inliers = 501, cond(F) = 3.9e+18\n",
            "[debug] 101-102 matches = 506\n",
            "[debug]     inliers = 459, cond(F) = 1.5e+17\n",
            "[debug] 102-103 matches = 592\n",
            "[debug]     inliers = 554, cond(F) = 1.2e+17\n",
            "[debug] 103-104 matches = 654\n",
            "[debug]     inliers = 613, cond(F) = 2.4e+18\n",
            "[debug] 103-105 matches = 588\n",
            "[debug]     inliers = 508, cond(F) = 1.3e+17\n",
            "[debug] 105-106 matches = 831\n",
            "[debug]     inliers = 761, cond(F) = 2.6e+17\n",
            "[debug] 106-107 matches = 799\n",
            "[debug]     inliers = 752, cond(F) = 8.0e+17\n",
            "[debug] 107-108 matches = 822\n",
            "[debug]     inliers = 747, cond(F) = inf\n",
            "[debug] 107-109 matches = 738\n",
            "[debug]     inliers = 655, cond(F) = 1.0e+17\n",
            "[debug] 109-110 matches = 674\n",
            "[debug]     inliers = 624, cond(F) = 3.8e+16\n",
            "[debug] 109-111 matches = 691\n",
            "[debug]     inliers = 635, cond(F) = 8.4e+16\n",
            "[debug] 111-112 matches = 648\n",
            "[debug]     inliers = 604, cond(F) = 1.5e+17\n",
            "[debug] 112-113 matches = 653\n",
            "[debug]     inliers = 544, cond(F) = 1.1e+17\n",
            "[debug] 113-114 matches = 917\n",
            "[debug]     inliers = 757, cond(F) = 9.8e+17\n",
            "[debug] 114-115 matches = 916\n",
            "[debug]     inliers = 872, cond(F) = 1.0e+17\n",
            "[debug] 115-116 matches = 829\n",
            "[debug]     inliers = 718, cond(F) = 5.2e+16\n",
            "[debug] 115-117 matches = 835\n",
            "[debug]     inliers = 744, cond(F) = 2.1e+16\n",
            "[warn] Skipping weak pair at 115-116\n",
            "[debug] 116-117 matches = 818\n",
            "[debug]     inliers = 752, cond(F) = 2.0e+16\n",
            "[debug] 116-118 matches = 859\n",
            "[debug]     inliers = 794, cond(F) = 3.1e+17\n",
            "[warn] Skipping weak pair at 116-117\n",
            "[debug] 117-118 matches = 837\n",
            "[debug]     inliers = 757, cond(F) = 5.2e+16\n",
            "[debug] 117-119 matches = 618\n",
            "[debug]     inliers = 566, cond(F) = 6.3e+18\n",
            "[debug] 119-120 matches = 707\n",
            "[debug]     inliers = 620, cond(F) = 9.6e+16\n",
            "[debug] 120-121 matches = 890\n",
            "[debug]     inliers = 798, cond(F) = 7.3e+17\n",
            "[debug] 120-122 matches = 797\n",
            "[debug]     inliers = 710, cond(F) = 6.8e+16\n",
            "[debug] 122-123 matches = 845\n",
            "[debug]     inliers = 743, cond(F) = 3.3e+16\n",
            "[debug] 122-124 matches = 794\n",
            "[debug]     inliers = 721, cond(F) = 2.8e+20\n",
            "[warn] Skipping weak pair at 122-123\n",
            "[debug] 123-124 matches = 915\n",
            "[debug]     inliers = 864, cond(F) = 2.3e+16\n",
            "[debug] 123-125 matches = 824\n",
            "[debug]     inliers = 677, cond(F) = 1.4e+17\n",
            "[warn] Skipping weak pair at 123-124\n",
            "[debug] 124-125 matches = 868\n",
            "[debug]     inliers = 713, cond(F) = 2.6e+17\n",
            "[debug] 124-126 matches = 859\n",
            "[debug]     inliers = 683, cond(F) = 2.1e+17\n",
            "[debug] 126-127 matches = 918\n",
            "[debug]     inliers = 843, cond(F) = 5.8e+16\n",
            "[debug] 126-128 matches = 832\n",
            "[debug]     inliers = 773, cond(F) = 3.4e+16\n",
            "[warn] Skipping weak pair at 126-127\n",
            "[debug] 127-128 matches = 902\n",
            "[debug]     inliers = 832, cond(F) = 9.8e+15\n",
            "[debug] 127-129 matches = 636\n",
            "[debug]     inliers = 553, cond(F) = 1.3e+18\n",
            "[debug] 129-130 matches = 649\n",
            "[debug]     inliers = 553, cond(F) = 3.8e+16\n",
            "[debug] 130-131 matches = 788\n",
            "[debug]     inliers = 698, cond(F) = 7.2e+16\n",
            "[debug] 131-132 matches = 931\n",
            "[debug]     inliers = 871, cond(F) = 8.6e+15\n",
            "[debug] 131-133 matches = 847\n",
            "[debug]     inliers = 731, cond(F) = 1.7e+16\n",
            "[warn] Skipping weak pair at 131-132\n",
            "[debug] 132-133 matches = 933\n",
            "[debug]     inliers = 875, cond(F) = 1.8e+16\n",
            "[debug] 132-134 matches = 854\n",
            "[debug]     inliers = 727, cond(F) = 4.6e+16\n",
            "[warn] Skipping weak pair at 132-133\n",
            "[debug] 133-134 matches = 908\n",
            "[debug]     inliers = 856, cond(F) = 1.4e+16\n",
            "[debug] 133-135 matches = 872\n",
            "[debug]     inliers = 772, cond(F) = 7.4e+16\n",
            "[warn] Skipping weak pair at 133-134\n",
            "[debug] 134-135 matches = 912\n",
            "[debug]     inliers = 856, cond(F) = 3.9e+16\n",
            "[debug] 134-136 matches = 824\n",
            "[debug]     inliers = 642, cond(F) = 1.2e+16\n",
            "[warn] Skipping weak pair at 134-135\n",
            "[debug] 135-136 matches = 930\n",
            "[debug]     inliers = 699, cond(F) = 7.0e+16\n",
            "[debug] 135-137 matches = 866\n",
            "[debug]     inliers = 646, cond(F) = 5.4e+18\n",
            "[debug] 137-138 matches = 958\n",
            "[debug]     inliers = 865, cond(F) = 8.3e+16\n",
            "[debug] 137-139 matches = 932\n",
            "[debug]     inliers = 826, cond(F) = 6.7e+17\n",
            "[debug] 139-140 matches = 1069\n",
            "[debug]     inliers = 951, cond(F) = 2.1e+17\n",
            "[debug] 140-141 matches = 1024\n",
            "[debug]     inliers = 934, cond(F) = 7.7e+15\n",
            "[debug] 140-142 matches = 898\n",
            "[debug]     inliers = 817, cond(F) = 7.1e+17\n",
            "[debug] 142-143 matches = 1005\n",
            "[debug]     inliers = 936, cond(F) = 5.9e+16\n",
            "[debug] 142-144 matches = 899\n",
            "[debug]     inliers = 832, cond(F) = 3.7e+16\n",
            "[debug] 144-145 matches = 860\n",
            "[debug]     inliers = 782, cond(F) = 5.0e+16\n",
            "[debug] 144-146 matches = 747\n",
            "[debug]     inliers = 639, cond(F) = 1.8e+17\n",
            "[warn] Skipping weak pair at 144-145\n",
            "[debug] 145-146 matches = 761\n",
            "[debug]     inliers = 653, cond(F) = 2.2e+16\n",
            "[debug] 145-147 matches = 779\n",
            "[debug]     inliers = 664, cond(F) = 3.4e+16\n",
            "[warn] Skipping weak pair at 145-146\n",
            "[debug] 146-147 matches = 795\n",
            "[debug]     inliers = 710, cond(F) = 1.7e+17\n",
            "[debug] 147-148 matches = 936\n",
            "[debug]     inliers = 859, cond(F) = 1.4e+17\n",
            "[debug] 147-149 matches = 909\n",
            "[debug]     inliers = 748, cond(F) = 2.0e+17\n",
            "[warn] Skipping weak pair at 147-148\n",
            "[debug] 148-149 matches = 984\n",
            "[debug]     inliers = 871, cond(F) = 3.6e+16\n",
            "Good pairs: 86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate initial focal length from Fundamental matrix via grid search and SVD analysis\n",
        "def estimate_focal_from_F(F, H, W, cx, cy):\n",
        "    # Construct intrinsic matrix with given focal length and fixed principal point\n",
        "    def score(f):\n",
        "        K = np.array([[f,0,cx],[0,f,cy],[0,0,1.0]], float)\n",
        "        E = K.T @ F @ K\n",
        "        _, s, _ = np.linalg.svd(E)\n",
        "        return (s[0]-s[1])**2 + (s[2])**2\n",
        "\n",
        "    # Initial grid search range: 60% to 250% of max image dimension\n",
        "    maxWH = float(max(W,H))\n",
        "    lo, hi = 0.6*maxWH, 2.5*maxWH\n",
        "    grid = np.linspace(lo, hi, 20)\n",
        "    vals = [score(f) for f in grid]\n",
        "\n",
        "    # Select best candidate based on minimum score\n",
        "    f = grid[int(np.argmin(vals))]\n",
        "\n",
        "    # Local refinement with decreasing step size\n",
        "    for step in [0.25, 0.1, 0.05, 0.02]:\n",
        "        span = step*maxWH\n",
        "        loc = np.linspace(max(lo, f-span), min(hi, f+span), 10)\n",
        "        f = loc[int(np.argmin([score(ff) for ff in loc]))]\n",
        "    return float(f)\n",
        "\n",
        "f_cands = []\n",
        "\n",
        "# For each good fundamental matrix, attempt to estimate focal length\n",
        "for _,_,_,F in good_pairs:\n",
        "    try:\n",
        "        f_cands.append(estimate_focal_from_F(F, H, W, cx, cy))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# Aggregate and validate focal length estimates\n",
        "min_f = 0.6*max(W,H)\n",
        "if len(f_cands)==0:\n",
        "    f_init = 1.2*max(W,H)\n",
        "else:\n",
        "    f_init = float(np.median(f_cands))\n",
        "    if not np.isfinite(f_init) or f_init < min_f:\n",
        "        f_init = 1.0*max(W,H)\n",
        "\n",
        "# Initialize intrinsics matrix K with estimated focal length\n",
        "fx = float(f_init)\n",
        "fy = float(f_init)\n",
        "K  = np.array([[fx, 0, cx],\n",
        "               [0,  fy, cy],\n",
        "               [0,   0,  1.0]], float)\n",
        "K_prior = (fx, fy, cx, cy)\n",
        "print(f\"[Init intrinsics] f≈{fx:.1f} px, cx={cx:.1f}, cy={cy:.1f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPcBscwVY6Uk",
        "outputId": "8c5942c4-772e-4d5c-ed06-dfb9a69f045d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Init intrinsics] f≈443.4 px, cx=369.5, cy=229.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Triangulates 3D points from corresponding normalized image coordinates\n",
        "def triangulate_points(P0, P1, x0, x1):\n",
        "    x0_h = np.vstack([x0.T, np.ones((1,x0.shape[0]))])\n",
        "    x1_h = np.vstack([x1.T, np.ones((1,x1.shape[0]))])\n",
        "    X_h = cv2.triangulatePoints(P0, P1, x0_h[:2,:], x1_h[:2,:])\n",
        "    X = (X_h[:3,:]/X_h[3,:]).T.copy()\n",
        "    return X\n",
        "\n",
        "# Computes the median parallax angle between rays originating from two camera positions to each triangulated 3D point\n",
        "def parallax_angle(R, t, pts3d):\n",
        "    \"\"\"\n",
        "    Estimates median parallax angle between rays from two cameras to 3D points.\n",
        "    R, t: rotation and translation from camera 1 to 2\n",
        "    pts3d: Nx3 triangulated 3D points (in world frame of camera 1)\n",
        "    Returns angle in degrees.\n",
        "    \"\"\"\n",
        "    rays1 = pts3d / np.linalg.norm(pts3d, axis=1, keepdims=True)\n",
        "    rays2 = ((R @ pts3d.T) + t.reshape(3, 1)).T\n",
        "    rays2 = rays2 / np.linalg.norm(rays2, axis=1, keepdims=True)\n",
        "\n",
        "    cos_angles = np.clip(np.sum(rays1 * rays2, axis=1), -1.0, 1.0)\n",
        "    angles_rad = np.arccos(cos_angles)\n",
        "    return np.median(angles_rad) * 180.0 / np.pi  # degrees\n",
        "\n",
        "# Projects 3D points X into 2D image coordinates using camera intrinsics K and extrinsic parameters given by rvec and tvec\n",
        "def project_points(X, rvec, tvec, K):\n",
        "    img_pts, _ = cv2.projectPoints(X.astype(np.float32),\n",
        "                                   rvec.reshape(3,1).astype(np.float32),\n",
        "                                   tvec.reshape(3,1).astype(np.float32),\n",
        "                                   K.astype(np.float32), None)\n",
        "    return img_pts.reshape(-1,2)\n",
        "\n",
        "# Camera poses, 3D points and observations initialization\n",
        "poses: Dict[int, Tuple[np.ndarray,np.ndarray]] = {}\n",
        "points3d: Dict[int, np.ndarray] = {}\n",
        "observations: Dict[int, List[Tuple[int, np.ndarray]]] = {}\n",
        "\n",
        "# Select first seed pair (i0, j0) and estimate relative pose\n",
        "i0, j0, matches0, F01 = good_pairs[0]\n",
        "pts1 = np.array([frames[i0].kps[m.queryIdx].pt for m in matches0], np.float32)\n",
        "pts2 = np.array([frames[j0].kps[m.trainIdx].pt for m in matches0], np.float32)\n",
        "E = K.T @ F01 @ K\n",
        "_, R01, t01, inl01 = cv2.recoverPose(\n",
        "    E,\n",
        "    cv2.undistortPoints(pts1.reshape(-1,1,2), K, None),\n",
        "    cv2.undistortPoints(pts2.reshape(-1,1,2), K, None)\n",
        ")\n",
        "inl01 = inl01.ravel().astype(bool)\n",
        "\n",
        "# Check if there is enough parallax between rays in the first pair\n",
        "x1n_seed = normalize_points(pts1[inl01], K)\n",
        "x2n_seed = normalize_points(pts2[inl01], K)\n",
        "b1 = np.column_stack([x1n_seed, np.ones(len(x1n_seed))])\n",
        "b2 = (R01 @ np.column_stack([x2n_seed, np.ones(len(x2n_seed))]).T).T\n",
        "b1 /= np.linalg.norm(b1, axis=1, keepdims=True)\n",
        "b2 /= np.linalg.norm(b2, axis=1, keepdims=True)\n",
        "ang = np.degrees(np.arccos(np.clip(np.sum(b1*b2, axis=1), -1, 1)))\n",
        "if np.median(ang) < 3.0:\n",
        "    raise RuntimeError(\"Seed pair has too little parallax; increase STRIDE or choose another start.\")\n",
        "\n",
        "# Initialize first two camera poses\n",
        "poses[i0] = (np.zeros(3), np.zeros(3))\n",
        "rvec1, _ = cv2.Rodrigues(R01)\n",
        "poses[j0] = (rvec1.ravel(), t01.ravel())\n",
        "\n",
        "# Triangulate initial 3D points from first good pair\n",
        "x1n = normalize_points(pts1[inl01], K)\n",
        "x2n = normalize_points(pts2[inl01], K)\n",
        "P0 = np.hstack([np.eye(3), np.zeros((3,1))])\n",
        "P1 = np.hstack([R01, t01])\n",
        "X01 = triangulate_points(P0, P1, x1n, x2n)\n",
        "angle = parallax_angle(R01, t01, X01)\n",
        "\n",
        "# Filter out 3D points based on cheirality and reprojection error\n",
        "def _repr_err(R, t, X, m):\n",
        "    pr = project_points(X[None,:], cv2.Rodrigues(R)[0].ravel()*0 + 0, t, K)[0] if X.ndim==1 else project_points(X, np.zeros(3), t, K)\n",
        "    return np.linalg.norm(pr - m, axis=-1)\n",
        "\n",
        "# Filter and validate initial triangulated 3D points between first two frames\n",
        "kept = 0\n",
        "for j, X in enumerate(X01):\n",
        "    z0 = (np.eye(3) @ X + np.zeros(3))[2]\n",
        "    z1 = (R01 @ X + t01.ravel())[2]\n",
        "    if z0 <= 0 or z1 <= 0:\n",
        "        continue\n",
        "\n",
        "    # Reprojection error sanity check for both views\n",
        "    pr0 = project_points(X[None,:], np.zeros(3), np.zeros(3), K)[0]\n",
        "    pr1 = project_points(X[None,:], cv2.Rodrigues(R01)[0].ravel(), t01.ravel(), K)[0]\n",
        "    if np.linalg.norm(pr0 - pts1[inl01][j]) < 2.5 and np.linalg.norm(pr1 - pts2[inl01][j]) < 2.5:\n",
        "        pid = len(points3d)\n",
        "        points3d[pid] = X\n",
        "        observations[pid] = [(i0, pts1[inl01][j]), (j0, pts2[inl01][j])]\n",
        "        kept += 1\n",
        "if kept < 50:\n",
        "    print(f\"[warn] Few seed 3D points kept: {kept}\")\n",
        "\n",
        "# Begin incremental reconstruction using remaining good image pairs\n",
        "for (ia, ib, matches, F_ab) in good_pairs[1:]:\n",
        "    f_cur, f_nxt = frames[ia], frames[ib]\n",
        "    pts2d, pts3d_list = [], []\n",
        "    for m in matches:\n",
        "        pt_cur = np.array(f_cur.kps[m.queryIdx].pt)\n",
        "\n",
        "        # Brute-force matching to associate 2D-3D correspondences\n",
        "        found = False\n",
        "        for pid, obs in observations.items():\n",
        "            if any((fi==ia and np.linalg.norm(meas-pt_cur) < 0.5) for (fi,meas) in obs):\n",
        "                pts3d_list.append(points3d[pid])\n",
        "                pts2d.append(f_nxt.kps[m.trainIdx].pt)\n",
        "                found = True\n",
        "                break\n",
        "    if len(pts3d_list) >= 6:\n",
        "        success, rvec, tvec, inl = cv2.solvePnPRansac(\n",
        "          np.array(pts3d_list, np.float32), np.array(pts2d, np.float32),\n",
        "          K, None, iterationsCount=2000, reprojectionError=2.5, confidence=0.999\n",
        "        )\n",
        "\n",
        "        if not success:\n",
        "            # Recover pose directly from F matrix\n",
        "            p_a = np.array([f_cur.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "            p_b = np.array([f_nxt.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "            Eab = K.T @ F_ab @ K\n",
        "            _, R, t, _ = cv2.recoverPose(\n",
        "                Eab,\n",
        "                cv2.undistortPoints(p_a.reshape(-1,1,2), K, None),\n",
        "                cv2.undistortPoints(p_b.reshape(-1,1,2), K, None)\n",
        "            )\n",
        "            rvec, _ = cv2.Rodrigues(R); tvec = t\n",
        "    else:\n",
        "        # Estimate pose via essential matrix if too few correspondences\n",
        "        p_a = np.array([f_cur.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "        p_b = np.array([f_nxt.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "        Eab = K.T @ F_ab @ K\n",
        "        _, R, t, _ = cv2.recoverPose(\n",
        "            Eab,\n",
        "            cv2.undistortPoints(p_a.reshape(-1,1,2), K, None),\n",
        "            cv2.undistortPoints(p_b.reshape(-1,1,2), K, None)\n",
        "        )\n",
        "        rvec, _ = cv2.Rodrigues(R); tvec = t\n",
        "\n",
        "    # Reject views with insufficient parallax for reliable triangulation\n",
        "    pts_i = np.array([f_cur.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "    pts_j = np.array([f_nxt.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "    x_i_n = normalize_points(pts_i, K)\n",
        "    x_j_n = normalize_points(pts_j, K)\n",
        "\n",
        "    R_est, _ = cv2.Rodrigues(rvec)\n",
        "    b1 = np.column_stack([x_i_n, np.ones(len(x_i_n))])\n",
        "    b2 = (R_est @ np.column_stack([x_j_n, np.ones(len(x_j_n))]).T).T\n",
        "    b1 = b1 / np.linalg.norm(b1, axis=1, keepdims=True)\n",
        "    b2 = b2 / np.linalg.norm(b2, axis=1, keepdims=True)\n",
        "    ang = np.degrees(np.arccos(np.clip(np.sum(b1 * b2, axis=1), -1, 1)))\n",
        "    if np.median(ang) < 3.0:\n",
        "        continue\n",
        "\n",
        "    # Pose assignment\n",
        "    poses.setdefault(ia, (np.zeros(3), np.zeros(3)))\n",
        "    poses[ib] = (rvec.ravel(), tvec.ravel())\n",
        "\n",
        "    # Triangulate new points\n",
        "    R_i, _ = cv2.Rodrigues(poses[ia][0]); t_i = poses[ia][1].reshape(3,1)\n",
        "    R_j, _ = cv2.Rodrigues(poses[ib][0]); t_j = poses[ib][1].reshape(3,1)\n",
        "    P_i = np.hstack([R_i, t_i]); P_j = np.hstack([R_j, t_j])\n",
        "\n",
        "    pts_i = np.array([f_cur.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "    pts_j = np.array([f_nxt.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "    x_i = normalize_points(pts_i, K); x_j = normalize_points(pts_j, K)\n",
        "    X_ij = triangulate_points(P_i, P_j, x_i, x_j)\n",
        "\n",
        "    # Validate and store newly triangulated points\n",
        "    for k, Xk in enumerate(X_ij):\n",
        "        z_i = (R_i @ Xk + t_i.ravel())[2]\n",
        "        z_j = (R_j @ Xk + t_j.ravel())[2]\n",
        "        if z_i <= 0 or z_j <= 0:\n",
        "            continue\n",
        "\n",
        "        pr_i = project_points(Xk[None, :], poses[ia][0], poses[ia][1], K)[0]\n",
        "        pr_j = project_points(Xk[None, :], poses[ib][0], poses[ib][1], K)[0]\n",
        "\n",
        "        if (np.linalg.norm(pr_i - pts_i[k]) < 2.5) and (np.linalg.norm(pr_j - pts_j[k]) < 2.5):\n",
        "            matched_pid = None\n",
        "            pt_i = pts_i[k]\n",
        "\n",
        "            for pid, obs in observations.items():\n",
        "                for cam_id, pt in obs:\n",
        "                    if cam_id == ia and np.linalg.norm(pt - pt_i) < 0.8:\n",
        "                        matched_pid = pid\n",
        "                        break\n",
        "                if matched_pid is not None:\n",
        "                    break\n",
        "\n",
        "            if matched_pid is not None:\n",
        "                # Associate this observation to an existing 3D point\n",
        "                observations[matched_pid].append((ib, pts_j[k]))\n",
        "            else:\n",
        "                # Register a new 3D point\n",
        "                pid = len(points3d)\n",
        "                points3d[pid] = Xk\n",
        "                observations.setdefault(pid, []).append((ia, pts_i[k]))\n",
        "                observations[pid].append((ib, pts_j[k]))\n",
        "\n"
      ],
      "metadata": {
        "id": "d2GrbUCLZIrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a335ec79-b5b8-4869-e284-4d3ffdbefddd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] Few seed 3D points kept: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accumulate all reprojection errors for each 3D point across all its observations\n",
        "all_errs = []\n",
        "track_err = {}\n",
        "\n",
        "# Iterate over all 3D points and their associated 2D observations\n",
        "for pid, obs in observations.items():\n",
        "    errs = []\n",
        "    for (fi, m_px) in obs:\n",
        "        if fi not in poses:\n",
        "            continue\n",
        "        rvec, tvec = poses[fi]\n",
        "\n",
        "        # Project the 3D point into the image using the current estimated camera pose\n",
        "        pr = project_points(points3d[pid][None,:], rvec, tvec, K)[0]\n",
        "        errs.append(float(np.linalg.norm(pr - m_px)))\n",
        "    if errs:\n",
        "        track_err[pid] = errs\n",
        "        all_errs.extend(errs)\n",
        "\n",
        "# Detect outliers using robust statistics\n",
        "if all_errs:\n",
        "    # Compute first and third quartile of reprojection errors\n",
        "    q1, q3 = np.percentile(all_errs, [25, 75])\n",
        "    iqr = max(q3 - q1, 1e-6)\n",
        "    thr = q3 + 2.0*iqr\n",
        "\n",
        "    # Remove outlier observations for each 3D point\n",
        "    for pid, errs in list(track_err.items()):\n",
        "        keep_obs = []\n",
        "        for (fi, m_px), e in zip(observations[pid], errs):\n",
        "            if e < thr:\n",
        "                keep_obs.append((fi, m_px))\n",
        "        if len(keep_obs) >= 2:\n",
        "            observations[pid] = keep_obs\n",
        "        else:\n",
        "            observations.pop(pid, None)\n",
        "            points3d.pop(pid, None)\n"
      ],
      "metadata": {
        "id": "2TubjIJ882Lq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from scipy.optimize import least_squares\n",
        "    SCIPY_OK = True\n",
        "except Exception:\n",
        "    SCIPY_OK = False\n",
        "\n",
        "# Refine focal length and principal point\n",
        "def ba_refine_f_cx_cy(observations, poses, points3d, f0, cx0, cy0, W, H):\n",
        "    if not SCIPY_OK:\n",
        "        return f0, cx0, cy0\n",
        "\n",
        "    # Collect all valid 3D-2D correspondences\n",
        "    obs_list = []\n",
        "    for pid, obs in observations.items():\n",
        "        X = points3d[pid]\n",
        "        for (fi, m_px) in obs:\n",
        "            if fi in poses:\n",
        "                rvec, tvec = poses[fi]\n",
        "                obs_list.append((X, rvec, tvec, m_px))\n",
        "    if len(obs_list) < 40:\n",
        "        return f0, cx0, cy0\n",
        "    print(f\"[BA] observations used: {len(obs_list)}\")\n",
        "\n",
        "    # Define residuals for least-squares optimization\n",
        "    def residuals(theta):\n",
        "        f, cx_fit, cy_fit = theta\n",
        "        K_loc = np.array([[f,0,cx_fit],[0,f,cy_fit],[0,0,1.0]], float)\n",
        "        res = []\n",
        "\n",
        "        # Reprojection errors per observation\n",
        "        for X, rvec, tvec, m_px in obs_list:\n",
        "            pr, _ = cv2.projectPoints(np.asarray(X).astype(np.float32),\n",
        "                                      rvec.reshape(3,1).astype(np.float32),\n",
        "                                      tvec.reshape(3,1).astype(np.float32),\n",
        "                                      K_loc.astype(np.float32), None)\n",
        "            pr = pr.reshape(-1,2)[0]\n",
        "            res.extend((pr - m_px).tolist())\n",
        "\n",
        "        # Soft regularization: encourage cx,cy to be near image center\n",
        "        lam_c = 1e-1\n",
        "        res.append(lam_c * ((cx_fit - (W*0.5)) / (0.5*W)))\n",
        "        res.append(lam_c * ((cy_fit - (H*0.5)) / (0.5*H)))\n",
        "\n",
        "        # Soft prior on f to stay near initial estimate\n",
        "        lam_f = 1e-4\n",
        "        res.append(lam_f * ((f - f0) / max(W, H)))\n",
        "\n",
        "        return np.array(res, float)\n",
        "\n",
        "    # Define search bounds and initial guess\n",
        "    f_lo = 0.6*max(W,H); f_hi = 3.0*max(W,H)\n",
        "    cx_lo, cx_hi = 0.3*W, 0.7*W\n",
        "    cy_lo, cy_hi = 0.3*H, 0.7*H\n",
        "    x0 = np.array([f0, np.clip(cx0, cx_lo, cx_hi), np.clip(cy0, cy_lo, cy_hi)], float)\n",
        "\n",
        "    # Run least-squares optimizer\n",
        "    try:\n",
        "        res = least_squares(residuals, x0=x0,\n",
        "                            bounds=([f_lo, cx_lo, cy_lo], [f_hi, cx_hi, cy_hi]),\n",
        "                            loss=\"soft_l1\", f_scale=2.0, max_nfev=200, verbose=0)\n",
        "        f, cx, cy = map(float, res.x)\n",
        "    except Exception:\n",
        "        f, cx, cy = f0, cx0, cy0\n",
        "    return f, cx, cy\n",
        "\n",
        "# Apply BA-based refinement to intrinsics\n",
        "f_refined, cx_ref, cy_ref = ba_refine_f_cx_cy(\n",
        "    observations, poses, points3d, f_init, cx, cy, W, H\n",
        ")\n",
        "\n",
        "# Final clipping and safety checks for intrinsics\n",
        "f_floor = 0.6*max(W,H)\n",
        "if not np.isfinite(f_refined) or f_refined < f_floor:\n",
        "    f_refined = max(f_init, 0.8*max(W,H))\n",
        "\n",
        "cx_ref = float(np.clip(cx_ref, 0.3*W, 0.7*W))\n",
        "cy_ref = float(np.clip(cy_ref, 0.3*H, 0.7*H))\n",
        "\n",
        "# Final K matrix construction\n",
        "K_ref = np.array([[f_refined, 0.0, cx_ref],\n",
        "                  [0.0,      f_refined, cy_ref],\n",
        "                  [0.0,      0.0,       1.0]], dtype=np.float64)\n",
        "\n",
        "K = K_ref.copy()\n",
        "fx, fy, cx, cy = float(K[0,0]), float(K[1,1]), float(K[0,2]), float(K[1,2])\n",
        "\n",
        "assert abs(fx - f_refined) < 1e-6 and abs(fy - f_refined) < 1e-6, \"fx/fy != f_refined\"\n",
        "assert abs(cx - cx_ref)    < 1e-6 and abs(cy - cy_ref)    < 1e-6, \"cx/cy != cx_ref/cy_ref\"\n",
        "\n",
        "print(f\"[Refined intrinsics] f≈{fx:.1f} px, cx={cx:.1f}, cy={cy:.1f}\")\n",
        "\n",
        "out_dir = \"/content/out_sfm\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "np.save(os.path.join(out_dir, \"K.npy\"), K)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFDb4oniasgl",
        "outputId": "904dc720-0eb2-443e-c95d-9a6d8a004505"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BA] observations used: 32630\n",
            "[Refined intrinsics] f≈443.4 px, cx=369.5, cy=229.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_est = np.load(\"/content/out_sfm/K.npy\")\n",
        "fx_e, fy_e, cx_e, cy_e = K_est[0,0], K_est[1,1], K_est[0,2], K_est[1,2]\n",
        "\n",
        "seq_dir = str(pathlib.Path(rgb_dir).parent)\n",
        "calib_path = os.path.join(seq_dir, \"calibration.txt\")\n",
        "print(\"calibration.txt:\", calib_path, os.path.exists(calib_path))\n",
        "\n",
        "fx_gt=fy_gt=cx_gt=cy_gt=None\n",
        "if os.path.exists(calib_path):\n",
        "    with open(calib_path, \"r\") as f:\n",
        "        txt = f.read()\n",
        "    nums = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", txt)\n",
        "    vals = list(map(float, nums))\n",
        "    for i in range(len(vals)-3):\n",
        "        fx_gt, fy_gt, cx_gt, cy_gt = vals[i:i+4]\n",
        "        if 50 < fx_gt < 20000 and 50 < fy_gt < 20000:\n",
        "            break\n",
        "\n",
        "    if fx_gt is not None:\n",
        "        rel_fx = abs(fx_e - fx_gt)/fx_gt\n",
        "        rel_fy = abs(fy_e - fy_gt)/fy_gt\n",
        "        dx = abs(cx_e - cx_gt); dy = abs(cy_e - cy_gt)\n",
        "\n",
        "        print(f\"[GT compare] fx: est={fx_e:.1f} gt={fx_gt:.1f}  rel.err={100*rel_fx:.2f}%\")\n",
        "        print(f\"[GT compare] fy: est={fy_e:.1f} gt={fy_gt:.1f}  rel.err={100*rel_fy:.2f}%\")\n",
        "        print(f\"[GT compare] cx: est={cx_e:.1f} gt={cx_gt:.1f}  |Δ|={dx:.2f}px\")\n",
        "        print(f\"[GT compare] cy: est={cy_e:.1f} gt={cy_gt:.1f}  |Δ|={dy:.2f}px\")\n",
        "    else:\n",
        "        print(\"Ground-truth intrinsics not parsed; check file format.\")\n",
        "else:\n",
        "    print(\"No ground truth file found for this sequence (test set or different layout).\")\n"
      ],
      "metadata": {
        "id": "dLJtAPH-cxFK",
        "outputId": "09d385c1-d6a6-4a54-d86d-bc92f9d8438a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calibration.txt: /content/eth3d/training/einstein_1/calibration.txt True\n",
            "[GT compare] fx: est=443.4 gt=726.3  rel.err=38.95%\n",
            "[GT compare] fy: est=443.4 gt=726.3  rel.err=38.95%\n",
            "[GT compare] cx: est=369.5 gt=354.6  |Δ|=14.85px\n",
            "[GT compare] cy: est=229.0 gt=186.5  |Δ|=42.53px\n"
          ]
        }
      ]
    }
  ]
}