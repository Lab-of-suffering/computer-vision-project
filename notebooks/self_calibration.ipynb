{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZPkZ_v_Gld4"
      },
      "source": [
        "Implementation of the self-calibration pipeline on an ETH3D SLAM dataset.  \n",
        "Given only a sequence of RGB images from a single moving camera, it:\n",
        "1. Loads an ETH3D monocular sequence, applies frame stride / frame cap, and resizes copies of frames for feature extraction.\n",
        "2. Detects local features (SIFT/ORB) and matches them between frames.\n",
        "3. Finds consistent frame pairs and estimates Fundamental matrices (F) using mutual matches, RANSAC, and parallax checks.\n",
        "4. Estimates the camera intrinsics K (focal length and principal point) from epipolar geometry using an SVD-based score and a 1D search over f (with fallback to a heuristic prior if too few stable F are available).\n",
        "5. Initializes two seed camera poses from a high-parallax pair, checks cheirality, and triangulates initial 3D points.\n",
        "6. Grows the model across frames using PnP on 2D–3D correspondences induced by existing 3D tracks and inter-frame matches, then triangulates new points from matched keypoints between registered views.\n",
        "7. Filters outliers by reprojection error and positive depth, and builds a cleaned, capped observation set for optimization.\n",
        "8. Refines intrinsics with a fast intrinsics-only BA.\n",
        "9. Runs a small “full” BA on subsets (intrinsics + selected poses + selected 3D points) with a robust loss.\n",
        "10. Outputs the final intrinsics K and the reconstructed camera poses and 3D points (which can then be saved or visualized).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "LxgwdWnEM0PD"
      },
      "outputs": [],
      "source": [
        "!pip -q install opencv-python-headless==4.10.0.84 numpy scipy\n",
        "\n",
        "import os, sys, glob, json, shutil, zipfile, pathlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "cv2.setRNGSeed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvkIpTYcRjKK",
        "outputId": "ec3e8987-d9c7-49c2-b46a-e0db82bafa73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: https://www.eth3d.net/data/slam/datasets/einstein_1_mono.zip\n",
            "Images dir: /content/eth3d/training/einstein_1/rgb num imgs: 487\n"
          ]
        }
      ],
      "source": [
        "# Download a monocular sequence from the ETH3D SLAM dataset\n",
        "import urllib.request, os, zipfile\n",
        "\n",
        "root = \"/content/eth3d\"\n",
        "os.makedirs(root, exist_ok=True)\n",
        "name = \"einstein_1\"   # dataset's name\n",
        "# name = \"einstein_global_light_changes_2\"\n",
        "mono_url = f\"https://www.eth3d.net/data/slam/datasets/{name}_mono.zip\"\n",
        "dst_zip  = f\"{root}/{name}_mono.zip\"\n",
        "dst_dir  = f\"{root}/training\"\n",
        "\n",
        "os.makedirs(dst_dir, exist_ok=True)\n",
        "print(\"Downloading:\", mono_url)\n",
        "urllib.request.urlretrieve(mono_url, dst_zip)\n",
        "\n",
        "with zipfile.ZipFile(dst_zip, 'r') as z:\n",
        "    z.extractall(dst_dir)\n",
        "os.remove(dst_zip)\n",
        "\n",
        "# Locate folder with RGB images\n",
        "rgb_dir = glob.glob(f\"{dst_dir}/{name}/**/rgb\", recursive=True)[0]\n",
        "print(\"Images dir:\", rgb_dir, \"num imgs:\", len(glob.glob(rgb_dir+'/*.png')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHPURKBsT3LT",
        "outputId": "54cbf85f-4f9d-49c2-eb3f-a7fb550296a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 487 frames, HxW=458x739\n"
          ]
        }
      ],
      "source": [
        "# Load all PNG images from the RGB directory of ETH3D format\n",
        "img_paths = sorted(glob.glob(os.path.join(rgb_dir, \"*.png\")))\n",
        "assert len(img_paths) > 0, f\"No PNGs in {rgb_dir}\"\n",
        "images = [cv2.imread(p, cv2.IMREAD_COLOR) for p in img_paths]\n",
        "assert all(im is not None for im in images), \"Some images failed to load\"\n",
        "\n",
        "# Extract image dimensions\n",
        "H, W = images[0].shape[:2]\n",
        "print(f\"Loaded {len(images)} frames, HxW={H}x{W}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmdluZ-2W5lx",
        "outputId": "7d254380-fbf8-4b54-9fd4-0e059ebe320d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 122 frames after stride, HxW=458x739\n"
          ]
        }
      ],
      "source": [
        "# Define control parameters for speed/robustness\n",
        "STRIDE     = 4      # Downsample frame sequence by this stride\n",
        "MAX_FRAMES = 150    # Limit total number of frames\n",
        "TARGET_W   = 960   # Rescale width (used for feature extraction)\n",
        "FEATURE    = \"sift\" # Feature type: \"sift\" | \"orb\"\n",
        "\n",
        "# List of F-matrices that passed geometric checks (for self-calibration)\n",
        "F_candidates = []\n",
        "\n",
        "\n",
        "# Apply frame stride and limit number of frames\n",
        "images = images[::STRIDE][:MAX_FRAMES]\n",
        "H, W = images[0].shape[:2]\n",
        "cx, cy = W * 0.5, H * 0.5 # Principal point is assumed to be the image center\n",
        "print(f\"Using {len(images)} frames after stride, HxW={H}x{W}\")\n",
        "\n",
        "# Initialize intrinsic matrix K\n",
        "f0 = 1.2 * max(H, W)\n",
        "fx = float(f0)\n",
        "fy = float(f0)\n",
        "K = np.array([[fx, 0.0, cx],\n",
        "              [0.0, fy,  cy],\n",
        "              [0.0, 0.0, 1.0]], dtype=np.float64)\n",
        "\n",
        "# Store intrinsic priors (used later for regularization in Bundle Adjustment)\n",
        "K_prior = (fx, fy, cx, cy)\n",
        "\n",
        "\n",
        "# Data container for storing keypoints and descriptors per frame\n",
        "@dataclass\n",
        "class FrameData:\n",
        "    kps: List[cv2.KeyPoint] # List of keypoints detected in the image\n",
        "    desc: np.ndarray        # Corresponding descriptor matrix\n",
        "    pts_px: np.ndarray      # Pixel coordinates (N x 2) at original resolution\n",
        "\n",
        "# Create a feature extractor\n",
        "def create_feature(name=\"sift\"):\n",
        "    name = (name or \"sift\").lower()\n",
        "    if name == \"sift\":\n",
        "        try:\n",
        "            return cv2.SIFT_create(nfeatures=3000)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return cv2.ORB_create(nfeatures=3000, scaleFactor=1.2, nlevels=10, edgeThreshold=15, fastThreshold=7)\n",
        "\n",
        "# Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance image contrast\n",
        "def preprocess_gray(g):\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    return clahe.apply(g)\n",
        "\n",
        "# Convert an image to grayscale\n",
        "def to_gray(img):\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim==3 else img\n",
        "\n",
        "def match_descriptors(d1, d2, ratio=0.80, min_matches=50):\n",
        "    \"\"\"\n",
        "    Perform two-way descriptor matching:\n",
        "    - Forward: KNN + Lowe's ratio test.\n",
        "    - Reverse: 1-NN verification to ensure mutual correspondence.\n",
        "    Returns a list of matches that satisfy both filters.\n",
        "    \"\"\"\n",
        "    # Sanity checks to ensure both descriptor sets are non-empty\n",
        "    if d1 is None or d2 is None:\n",
        "        return []\n",
        "    if len(d1) == 0 or len(d2) == 0:\n",
        "        return []\n",
        "\n",
        "    # Choose matcher type based on descriptor data type\n",
        "    is_bin = (d1.dtype == np.uint8 and d2.dtype == np.uint8)\n",
        "    if is_bin:\n",
        "        matcher_fwd = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "        matcher_rev = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "        d1_use, d2_use = d1, d2\n",
        "        d2_use_rev, d1_use_rev = d2, d1\n",
        "    else:\n",
        "        d1_use = np.asarray(d1, dtype=np.float32)\n",
        "        d2_use = np.asarray(d2, dtype=np.float32)\n",
        "        d2_use_rev = d2_use\n",
        "        d1_use_rev = d1_use\n",
        "        index_params = dict(algorithm=1, trees=5)\n",
        "        search_params = dict(checks=64)\n",
        "        matcher_fwd = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "        matcher_rev = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Perform KNN matching (k=2) for Lowe's ratio filtering\n",
        "    knn = matcher_fwd.knnMatch(d1_use, d2_use, k=2)\n",
        "    ratio_pass = []\n",
        "    for pair in knn:\n",
        "        if len(pair) < 2:\n",
        "            continue\n",
        "        m, n = pair\n",
        "        if m.distance < ratio * n.distance:\n",
        "            ratio_pass.append(m)\n",
        "\n",
        "    if not ratio_pass:\n",
        "        return []\n",
        "\n",
        "    # Perform reverse 1-NN matching to check mutual correspondence\n",
        "    knn_rev = matcher_rev.knnMatch(d2_use_rev, d1_use_rev, k=1)\n",
        "    rev_map = {}\n",
        "    for pair in knn_rev:\n",
        "        if not pair:\n",
        "            continue\n",
        "        r = pair[0]\n",
        "        rev_map[r.queryIdx] = r.trainIdx\n",
        "\n",
        "    # Mutual match check: only retain matches where forward and reverse agree\n",
        "    mutual = []\n",
        "    seen = set()  # avoid duplicates\n",
        "    for m in ratio_pass:\n",
        "        if rev_map.get(m.trainIdx, -1) == m.queryIdx:\n",
        "            key = (m.queryIdx, m.trainIdx)\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                mutual.append(m)\n",
        "\n",
        "    # If mutual matches are too few, skip further processing\n",
        "    if len(mutual) < min_matches:\n",
        "        return []\n",
        "\n",
        "    return mutual\n",
        "\n",
        "# Robust estimation of the Fundamental matrix\n",
        "def ransac_F(pts1, pts2):\n",
        "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n",
        "                                     ransacReprojThreshold=3.0, confidence=0.995, maxIters=4000)\n",
        "    # Retry with more iterations if initial estimation fails\n",
        "    if F is None or F.shape!=(3,3):\n",
        "        F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n",
        "                                         ransacReprojThreshold=3.0, confidence=0.995, maxIters=8000)\n",
        "    mask = (mask.ravel().astype(bool) if mask is not None else np.zeros(len(pts1), bool))\n",
        "    return F, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlXwlA-bW-Ni",
        "outputId": "15eb6923-dd08-44a4-9896-1bfd2f722818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features extracted for 122 frames\n"
          ]
        }
      ],
      "source": [
        "feat = create_feature(FEATURE)\n",
        "\n",
        "# Initialize the list to store extracted feature information for each frame\n",
        "frames: List[FrameData] = []\n",
        "\n",
        "for img in images:\n",
        "    # Compute the scaling factor to resize the image to the target working width\n",
        "    scale = min(1.0, TARGET_W / float(img.shape[1]))\n",
        "    img_small = cv2.resize(img, (int(img.shape[1]*scale), int(img.shape[0]*scale)),\n",
        "                           interpolation=cv2.INTER_AREA) if scale<1.0 else img\n",
        "    gray = preprocess_gray(to_gray(img_small))\n",
        "\n",
        "    # Detect keypoints and compute descriptors using the selected feature detector\n",
        "    kps_small, desc = feat.detectAndCompute(gray, None)\n",
        "\n",
        "    # Map keypoints back to original scale so the rest of geometry uses full-res pixels\n",
        "    kps, pts_px = [], []\n",
        "    inv = 1.0 / scale\n",
        "\n",
        "    if scale == 1.0:\n",
        "        # No scaling was applied\n",
        "        kps = kps_small\n",
        "        pts_px = [kp.pt for kp in kps_small]\n",
        "    else:\n",
        "        for kp in kps_small:\n",
        "            x = kp.pt[0] * inv\n",
        "            y = kp.pt[1] * inv\n",
        "\n",
        "            # Scale the keypoint size appropriately and preserve its original attributes\n",
        "            size   = max(1.0, kp.size * inv)\n",
        "            angle  = float(kp.angle) if kp.angle is not None else -1.0\n",
        "            resp   = float(kp.response)\n",
        "            octave = int(kp.octave)\n",
        "            clsid  = int(kp.class_id)\n",
        "\n",
        "            new_kp = cv2.KeyPoint(float(x), float(y), float(size), float(angle), resp, octave, clsid)\n",
        "\n",
        "            # Append the new keypoint and its position to the lists\n",
        "            kps.append(new_kp)\n",
        "            pts_px.append([x, y])\n",
        "\n",
        "    pts_px = np.array(pts_px, dtype=np.float32)\n",
        "    frames.append(FrameData(kps=kps, desc=desc, pts_px=pts_px))\n",
        "\n",
        "\n",
        "print(\"Features extracted for\", len(frames), \"frames\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARMGLwx6YvUM",
        "outputId": "b556df49-4f29-45f0-a0a2-02174b5b26f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[debug] 0-1 matches = 112\n",
            "[debug]     inliers = 97, cond(F) = 1.8e+17\n",
            "[debug] 1-2 matches = 115\n",
            "[debug]     inliers = 102, cond(F) = 6.4e+17\n",
            "[debug] 2-3 matches = 143\n",
            "[debug]     inliers = 130, cond(F) = 1.7e+17\n",
            "[debug] 3-4 matches = 170\n",
            "[debug]     inliers = 157, cond(F) = 3.0e+17\n",
            "[debug] 3-5 matches = 143\n",
            "[debug]     inliers = 129, cond(F) = 1.4e+18\n",
            "[debug] 5-6 matches = 197\n",
            "[debug]     inliers = 186, cond(F) = 8.9e+16\n",
            "[debug] 6-7 matches = 214\n",
            "[debug]     inliers = 203, cond(F) = 2.0e+17\n",
            "[debug] 7-8 matches = 252\n",
            "[debug]     inliers = 241, cond(F) = 5.6e+18\n",
            "[debug] 7-9 matches = 227\n",
            "[debug]     inliers = 201, cond(F) = 2.5e+17\n",
            "[debug] 9-10 matches = 211\n",
            "[debug]     inliers = 184, cond(F) = 8.0e+16\n",
            "[debug] 10-11 matches = 234\n",
            "[debug]     inliers = 217, cond(F) = 9.3e+17\n",
            "[debug] 11-12 matches = 285\n",
            "[debug]     inliers = 264, cond(F) = 1.2e+20\n",
            "[debug] 11-13 matches = 211\n",
            "[debug]     inliers = 194, cond(F) = 3.4e+18\n",
            "[debug] 13-14 matches = 249\n",
            "[debug]     inliers = 232, cond(F) = 1.2e+18\n",
            "[debug] 13-15 matches = 207\n",
            "[debug]     inliers = 173, cond(F) = 2.2e+16\n",
            "[debug] 15-16 matches = 241\n",
            "[debug]     inliers = 210, cond(F) = 1.4e+17\n",
            "[debug] 16-17 matches = 225\n",
            "[debug]     inliers = 203, cond(F) = 1.4e+18\n",
            "[debug] 17-18 matches = 242\n",
            "[debug]     inliers = 208, cond(F) = 3.3e+16\n",
            "[debug] 18-19 matches = 286\n",
            "[debug]     inliers = 249, cond(F) = 1.0e+16\n",
            "[debug] 19-20 matches = 388\n",
            "[debug]     inliers = 348, cond(F) = 1.4e+17\n",
            "[debug] 19-21 matches = 285\n",
            "[debug]     inliers = 241, cond(F) = 1.0e+18\n",
            "[warn] Skipping weak pair at 19-20\n",
            "[debug] 20-21 matches = 322\n",
            "[debug]     inliers = 299, cond(F) = 6.1e+15\n",
            "[debug] 20-22 matches = 326\n",
            "[debug]     inliers = 272, cond(F) = 3.7e+17\n",
            "[debug] 22-23 matches = 409\n",
            "[debug]     inliers = 382, cond(F) = 6.8e+16\n",
            "[debug] 22-24 matches = 412\n",
            "[debug]     inliers = 365, cond(F) = 1.6e+18\n",
            "[warn] Skipping weak pair at 22-23\n",
            "[debug] 23-24 matches = 404\n",
            "[debug]     inliers = 365, cond(F) = 6.0e+16\n",
            "[debug] 24-25 matches = 485\n",
            "[debug]     inliers = 447, cond(F) = 1.9e+17\n",
            "[debug] 25-26 matches = 430\n",
            "[debug]     inliers = 404, cond(F) = 8.4e+17\n",
            "[debug] 26-27 matches = 381\n",
            "[debug]     inliers = 332, cond(F) = 2.0e+18\n",
            "[debug] 27-28 matches = 329\n",
            "[debug]     inliers = 282, cond(F) = 2.0e+17\n",
            "[debug] 28-29 matches = 348\n",
            "[debug]     inliers = 316, cond(F) = 6.7e+16\n",
            "[debug] 28-30 matches = 321\n",
            "[debug]     inliers = 285, cond(F) = 6.4e+17\n",
            "[debug] 30-31 matches = 404\n",
            "[debug]     inliers = 306, cond(F) = 8.7e+18\n",
            "[debug] 31-32 matches = 384\n",
            "[debug]     inliers = 319, cond(F) = 2.2e+17\n",
            "[debug] 31-33 matches = 295\n",
            "[debug]     inliers = 258, cond(F) = 5.9e+17\n",
            "[debug] 33-34 matches = 386\n",
            "[debug]     inliers = 328, cond(F) = 4.8e+16\n",
            "[debug] 34-35 matches = 448\n",
            "[debug]     inliers = 376, cond(F) = 1.2e+17\n",
            "[debug] 35-36 matches = 446\n",
            "[debug]     inliers = 405, cond(F) = 7.9e+19\n",
            "[debug] 36-37 matches = 335\n",
            "[debug]     inliers = 287, cond(F) = 5.9e+18\n",
            "[debug] 37-38 matches = 354\n",
            "[debug]     inliers = 287, cond(F) = 2.0e+17\n",
            "[debug] 38-39 matches = 415\n",
            "[debug]     inliers = 335, cond(F) = 2.3e+17\n",
            "[debug] 39-40 matches = 452\n",
            "[debug]     inliers = 399, cond(F) = 6.0e+17\n",
            "[debug] 39-41 matches = 459\n",
            "[debug]     inliers = 398, cond(F) = 5.8e+18\n",
            "[debug] 41-42 matches = 580\n",
            "[debug]     inliers = 445, cond(F) = 5.6e+17\n",
            "[debug] 42-43 matches = 491\n",
            "[debug]     inliers = 444, cond(F) = 2.4e+17\n",
            "[debug] 43-44 matches = 442\n",
            "[debug]     inliers = 380, cond(F) = 3.1e+20\n",
            "[debug] 43-45 matches = 379\n",
            "[debug]     inliers = 315, cond(F) = 5.8e+17\n",
            "[debug] 45-46 matches = 502\n",
            "[debug]     inliers = 383, cond(F) = 3.3e+16\n",
            "[debug] 45-47 matches = 256\n",
            "[debug]     inliers = 184, cond(F) = 5.9e+17\n",
            "[debug] 47-48 matches = 316\n",
            "[debug]     inliers = 273, cond(F) = 1.8e+18\n",
            "[debug] 48-49 matches = 475\n",
            "[debug]     inliers = 396, cond(F) = 1.5e+19\n",
            "[debug] 49-50 matches = 406\n",
            "[debug]     inliers = 342, cond(F) = 2.9e+17\n",
            "[debug] 50-51 matches = 493\n",
            "[debug]     inliers = 427, cond(F) = 4.4e+18\n",
            "[debug] 51-52 matches = 430\n",
            "[debug]     inliers = 384, cond(F) = 6.1e+17\n",
            "[debug] 52-53 matches = 780\n",
            "[debug]     inliers = 725, cond(F) = 3.7e+17\n",
            "[debug] 53-54 matches = 739\n",
            "[debug]     inliers = 706, cond(F) = 8.0e+18\n",
            "[debug] 54-55 matches = 570\n",
            "[debug]     inliers = 489, cond(F) = 9.7e+16\n",
            "[debug] 55-56 matches = 522\n",
            "[debug]     inliers = 448, cond(F) = 1.5e+17\n",
            "[debug] 56-57 matches = 564\n",
            "[debug]     inliers = 413, cond(F) = 8.1e+17\n",
            "[debug] 57-58 matches = 798\n",
            "[debug]     inliers = 668, cond(F) = 1.6e+16\n",
            "[debug] 58-59 matches = 857\n",
            "[debug]     inliers = 803, cond(F) = 4.2e+16\n",
            "[debug] 59-60 matches = 827\n",
            "[debug]     inliers = 653, cond(F) = 4.0e+17\n",
            "[debug] 60-61 matches = 803\n",
            "[debug]     inliers = 761, cond(F) = 1.6e+17\n",
            "[debug] 61-62 matches = 794\n",
            "[debug]     inliers = 748, cond(F) = 2.2e+17\n",
            "[debug] 61-63 matches = 664\n",
            "[debug]     inliers = 485, cond(F) = 1.1e+17\n",
            "[debug] 63-64 matches = 826\n",
            "[debug]     inliers = 784, cond(F) = 5.9e+17\n",
            "[debug] 63-65 matches = 590\n",
            "[debug]     inliers = 468, cond(F) = 1.3e+18\n",
            "[debug] 65-66 matches = 692\n",
            "[debug]     inliers = 620, cond(F) = 5.7e+16\n",
            "[debug] 66-67 matches = 856\n",
            "[debug]     inliers = 760, cond(F) = 1.1e+16\n",
            "[debug] 66-68 matches = 741\n",
            "[debug]     inliers = 589, cond(F) = 5.3e+17\n",
            "[debug] 68-69 matches = 923\n",
            "[debug]     inliers = 790, cond(F) = 1.5e+18\n",
            "[debug] 68-70 matches = 850\n",
            "[debug]     inliers = 685, cond(F) = 1.8e+17\n",
            "[debug] 70-71 matches = 898\n",
            "[debug]     inliers = 784, cond(F) = 1.7e+18\n",
            "[debug] 71-72 matches = 905\n",
            "[debug]     inliers = 818, cond(F) = 7.8e+16\n",
            "[debug] 71-73 matches = 731\n",
            "[debug]     inliers = 600, cond(F) = 1.8e+17\n",
            "[debug] 73-74 matches = 737\n",
            "[debug]     inliers = 678, cond(F) = 3.4e+17\n",
            "[debug] 74-75 matches = 729\n",
            "[debug]     inliers = 624, cond(F) = 2.2e+19\n",
            "[debug] 75-76 matches = 649\n",
            "[debug]     inliers = 573, cond(F) = 1.5e+18\n",
            "[debug] 75-77 matches = 547\n",
            "[debug]     inliers = 405, cond(F) = 7.1e+17\n",
            "[debug] 77-78 matches = 709\n",
            "[debug]     inliers = 622, cond(F) = 1.2e+18\n",
            "[debug] 77-79 matches = 730\n",
            "[debug]     inliers = 590, cond(F) = 1.5e+16\n",
            "[warn] Skipping weak pair at 77-78\n",
            "[debug] 78-79 matches = 849\n",
            "[debug]     inliers = 757, cond(F) = 2.0e+17\n",
            "[debug] 78-80 matches = 741\n",
            "[debug]     inliers = 610, cond(F) = 3.5e+16\n",
            "[warn] Skipping weak pair at 78-79\n",
            "[debug] 79-80 matches = 844\n",
            "[debug]     inliers = 748, cond(F) = 2.0e+16\n",
            "[debug] 79-81 matches = 639\n",
            "[debug]     inliers = 560, cond(F) = 4.6e+16\n",
            "[info] Enough good pairs: 60. Stop.\n",
            "Good pairs: 60\n"
          ]
        }
      ],
      "source": [
        "# List to store high-quality image pairs with sufficient parallax and valid epipolar geometry\n",
        "good_pairs = []\n",
        "\n",
        "# Helper function to skip visually similar consecutive frames\n",
        "def frames_too_similar(i, j, thr=1.5):\n",
        "    g1 = to_gray(images[i]).astype(np.float32)\n",
        "    g2 = to_gray(images[j]).astype(np.float32)\n",
        "    return float(np.mean(np.abs(g1 - g2))) < thr\n",
        "\n",
        "# Main loop to iterate over the frame sequence and identify geometrically valid pairs\n",
        "i = 0\n",
        "while i < len(frames)-1:\n",
        "    tried = False\n",
        "\n",
        "    # Try pairing current frame with the next or the one after\n",
        "    for j in (i+1, i+2 if i+2 < len(frames) else i+1):\n",
        "        if j >= len(frames) or frames_too_similar(i,j):\n",
        "            continue\n",
        "        f1, f2 = frames[i], frames[j]\n",
        "\n",
        "        # Match descriptors with Lowe's ratio test + mutual check\n",
        "        matches = match_descriptors(f1.desc, f2.desc, ratio=0.85)\n",
        "        if len(matches) < 60:\n",
        "            continue\n",
        "\n",
        "        # Extract matched keypoint coordinates\n",
        "        pts1 = np.array([f1.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "        pts2 = np.array([f2.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "        F, mask = ransac_F(pts1, pts2)\n",
        "        inl = int(mask.sum())\n",
        "\n",
        "        print(f\"[debug] {i}-{j} matches = {len(matches)}\")\n",
        "        if F is not None:\n",
        "            print(f\"[debug]     inliers = {inl}, cond(F) = {np.linalg.cond(F):.1e}\")\n",
        "\n",
        "        # Check quality of fundamental matrix and number of inliers\n",
        "            if F is not None and inl >= 30 and np.linalg.cond(F) < 1e20:\n",
        "              good = [matches[k] for k in range(len(matches)) if mask[k]]\n",
        "\n",
        "              pts1_u = cv2.undistortPoints(\n",
        "                  pts1[mask].reshape(-1, 1, 2), K, None\n",
        "              ).reshape(-1, 2)\n",
        "              pts2_u = cv2.undistortPoints(\n",
        "                  pts2[mask].reshape(-1, 1, 2), K, None\n",
        "              ).reshape(-1, 2)\n",
        "\n",
        "              E_tmp = K.T @ F @ K\n",
        "\n",
        "              _, Rtmp, ttmp, _ = cv2.recoverPose(\n",
        "                  E_tmp,\n",
        "                  pts1_u.reshape(-1, 1, 2),\n",
        "                  pts2_u.reshape(-1, 1, 2),\n",
        "              )\n",
        "\n",
        "              b1 = np.column_stack([pts1_u, np.ones(len(pts1_u))])\n",
        "              b2 = (Rtmp @ np.column_stack([pts2_u, np.ones(len(pts2_u))]).T).T\n",
        "              b1 /= np.linalg.norm(b1, axis=1, keepdims=True)\n",
        "              b2 /= np.linalg.norm(b2, axis=1, keepdims=True)\n",
        "\n",
        "              ang = np.degrees(np.arccos(np.clip(np.sum(b1 * b2, axis=1), -1, 1)))\n",
        "              if np.median(ang) < 1.5:\n",
        "                  continue\n",
        "\n",
        "              good_pairs.append((i, j, good, F))\n",
        "\n",
        "              F_candidates.append(F.copy())\n",
        "\n",
        "              i = j\n",
        "              tried = True\n",
        "              break\n",
        "\n",
        "\n",
        "    if not tried:\n",
        "        print(f\"[warn] Skipping weak pair at {i}-{i+1}\")\n",
        "        i += 1\n",
        "    if len(good_pairs) >= 60:\n",
        "        print(f\"[info] Enough good pairs: {len(good_pairs)}. Stop.\")\n",
        "        break\n",
        "\n",
        "assert len(good_pairs) > 0, \"No good pairs found. Try larger STRIDE or different sequence.\"\n",
        "print(\"Good pairs:\", len(good_pairs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPcBscwVY6Uk",
        "outputId": "9c13d012-2122-4cb5-cc36-79dfecd9e324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SelfCal] Using 60 F-matrices for focal estimation\n",
            "[Focal] coarse search on [591.2, 1330.2] px, best≈591.20, score=3.183e-03\n",
            "[Focal] refine search on [591.2, 650.3] px, f≈591.20, score=3.183e-03\n",
            "[Init intrinsics] f≈591.2 px, cx=369.5, cy=229.0\n"
          ]
        }
      ],
      "source": [
        "# Estimate initial focal length from Fundamental matrix via grid search and SVD analysis\n",
        "def estimate_focal_from_F_list(F_list, W, H, verbose=True):\n",
        "    if len(F_list) < 3:\n",
        "        # Too few matrices for stable estimation\n",
        "        f_heur = 1.2 * max(W, H)\n",
        "        if verbose:\n",
        "            print(f\"[Focal] Not enough F-matrices ({len(F_list)}), fallback f≈{f_heur:.1f}\")\n",
        "        return float(f_heur)\n",
        "\n",
        "    maxWH = float(max(W, H))\n",
        "\n",
        "    def score_for_f(f):\n",
        "        # Build K(f)\n",
        "        K = np.array(\n",
        "            [\n",
        "                [f, 0.0, W * 0.5],\n",
        "                [0.0, f, H * 0.5],\n",
        "                [0.0, 0.0, 1.0],\n",
        "            ],\n",
        "            dtype=np.float64,\n",
        "        )\n",
        "\n",
        "        total = 0.0\n",
        "        count = 0\n",
        "        for F in F_list:\n",
        "            E = K.T @ F @ K\n",
        "            U, S, Vt = np.linalg.svd(E)\n",
        "            s1, s2, s3 = S\n",
        "\n",
        "            # Skip degenerate cases\n",
        "            if s1 <= 0.0 or s2 <= 0.0:\n",
        "                continue\n",
        "\n",
        "            num = (s1 - s2) ** 2 + s3 ** 2\n",
        "            den = s1 * s2\n",
        "            total += num / den\n",
        "            count += 1\n",
        "\n",
        "        if count == 0:\n",
        "            return np.inf\n",
        "        return total / count\n",
        "\n",
        "    f_min = 0.8 * maxWH\n",
        "    f_max = 1.8 * maxWH\n",
        "    n_samples = 50\n",
        "\n",
        "    f_grid = np.linspace(f_min, f_max, n_samples)\n",
        "    scores = []\n",
        "    for f in f_grid:\n",
        "        s = score_for_f(f)\n",
        "        scores.append(s)\n",
        "\n",
        "    scores = np.asarray(scores, dtype=np.float64)\n",
        "    best_idx = int(np.argmin(scores))\n",
        "    f_best = float(f_grid[best_idx])\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[Focal] coarse search on [{f_min:.1f}, {f_max:.1f}] px, \"\n",
        "              f\"best≈{f_best:.2f}, score={scores[best_idx]:.3e}\")\n",
        "\n",
        "    # Local refinement around the best f\n",
        "    width = (f_max - f_min) / n_samples * 4.0\n",
        "    f_ref_min = max(f_min, f_best - width)\n",
        "    f_ref_max = min(f_max, f_best + width)\n",
        "\n",
        "    n_ref = 30\n",
        "    f_ref_grid = np.linspace(f_ref_min, f_ref_max, n_ref)\n",
        "    ref_scores = []\n",
        "    for f in f_ref_grid:\n",
        "        s = score_for_f(f)\n",
        "        ref_scores.append(s)\n",
        "\n",
        "    ref_scores = np.asarray(ref_scores, dtype=np.float64)\n",
        "    best_idx2 = int(np.argmin(ref_scores))\n",
        "    f_opt = float(f_ref_grid[best_idx2])\n",
        "\n",
        "    if verbose:\n",
        "        print(\n",
        "            f\"[Focal] refine search on [{f_ref_min:.1f}, {f_ref_max:.1f}] px, \"\n",
        "            f\"f≈{f_opt:.2f}, score={ref_scores[best_idx2]:.3e}\"\n",
        "        )\n",
        "\n",
        "    return float(f_opt)\n",
        "\n",
        "\n",
        "F_list = [F for (_, _, _, F) in good_pairs]\n",
        "\n",
        "print(f\"[SelfCal] Using {len(F_list)} F-matrices for focal estimation\")\n",
        "\n",
        "if len(F_list) < 3:\n",
        "    f_init = 1.2 * max(W, H)\n",
        "    print(f\"[SelfCal] Not enough F-matrices ({len(F_list)}), fallback f≈{f_init:.1f}\")\n",
        "else:\n",
        "    f_init = estimate_focal_from_F_list(F_list, W, H, verbose=True)\n",
        "\n",
        "cx = W * 0.5\n",
        "cy = H * 0.5\n",
        "\n",
        "fx = float(f_init)\n",
        "fy = float(f_init)\n",
        "K  = np.array(\n",
        "    [\n",
        "        [fx, 0.0, cx],\n",
        "        [0.0, fy, cy],\n",
        "        [0.0, 0.0, 1.0],\n",
        "    ],\n",
        "    dtype=np.float64,\n",
        ")\n",
        "\n",
        "K_prior = (fx, fy, cx, cy)\n",
        "print(f\"[Init intrinsics] f≈{fx:.1f} px, cx={cx:.1f}, cy={cy:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2GrbUCLZIrE",
        "outputId": "29d5ef7c-be89-4230-ea1b-62359f15449e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[seed] using pair (0,1), parallax=7.79 deg, inliers=63\n",
            "[seed] 3D points kept after reproj filter: 63\n",
            "[seed] total seed 3D points kept: 63\n"
          ]
        }
      ],
      "source": [
        "# Triangulates 3D points from corresponding normalized image coordinates\n",
        "def triangulate_points(P0, P1, x0, x1):\n",
        "    x0_h = np.vstack([x0.T, np.ones((1,x0.shape[0]))])\n",
        "    x1_h = np.vstack([x1.T, np.ones((1,x1.shape[0]))])\n",
        "    X_h = cv2.triangulatePoints(P0, P1, x0_h[:2,:], x1_h[:2,:])\n",
        "    X = (X_h[:3,:]/X_h[3,:]).T.copy()\n",
        "    return X\n",
        "\n",
        "# Computes the median parallax angle between rays originating from two camera positions to each triangulated 3D point\n",
        "def parallax_angle(R, t, pts3d):\n",
        "    \"\"\"\n",
        "    Estimates median parallax angle between rays from two cameras to 3D points.\n",
        "    R, t: rotation and translation from camera 1 to 2\n",
        "    pts3d: Nx3 triangulated 3D points (in world frame of camera 1)\n",
        "    Returns angle in degrees.\n",
        "    \"\"\"\n",
        "    rays1 = pts3d / np.linalg.norm(pts3d, axis=1, keepdims=True)\n",
        "    rays2 = ((R @ pts3d.T) + t.reshape(3, 1)).T\n",
        "    rays2 = rays2 / np.linalg.norm(rays2, axis=1, keepdims=True)\n",
        "\n",
        "    cos_angles = np.clip(np.sum(rays1 * rays2, axis=1), -1.0, 1.0)\n",
        "    angles_rad = np.arccos(cos_angles)\n",
        "    return np.median(angles_rad) * 180.0 / np.pi  # degrees\n",
        "\n",
        "# Projects 3D points X into 2D image coordinates using camera intrinsics K and extrinsic parameters given by rvec and tvec\n",
        "def project_points(X, rvec, tvec, K):\n",
        "    img_pts, _ = cv2.projectPoints(X.astype(np.float32),\n",
        "                                   rvec.reshape(3,1).astype(np.float32),\n",
        "                                   tvec.reshape(3,1).astype(np.float32),\n",
        "                                   K.astype(np.float32), None)\n",
        "    return img_pts.reshape(-1,2)\n",
        "\n",
        "\n",
        "# Fast vectorized pinhole projection\n",
        "def pinhole_project_batch(f: float, cx: float, cy: float,\n",
        "                          R: np.ndarray, t: np.ndarray,\n",
        "                          X: np.ndarray) -> np.ndarray:\n",
        "    X = np.asarray(X, np.float64)\n",
        "    R = np.asarray(R, np.float64).reshape(3, 3)\n",
        "    t = np.asarray(t, np.float64).reshape(3,)\n",
        "    Xc = (R @ X.T).T + t\n",
        "    z  = np.clip(Xc[:, 2:3], 1e-9, None)\n",
        "    u  = Xc[:, :2] / z\n",
        "    u  = u * float(f) + np.array([cx, cy], dtype=np.float64)\n",
        "    return u\n",
        "\n",
        "\n",
        "# Select first seed pair (i0, j0) and estimate relative pose\n",
        "def choose_seed_pair(good_pairs, K, frames, min_parallax_deg=1.0):\n",
        "    \"\"\"\n",
        "    Select a seed-a pair of frames with sufficient parallax.\n",
        "    \"\"\"\n",
        "    for (i0, j0, matches0, F01) in good_pairs:\n",
        "        pts1 = np.array([frames[i0].kps[m.queryIdx].pt for m in matches0], np.float32)\n",
        "        pts2 = np.array([frames[j0].kps[m.trainIdx].pt for m in matches0], np.float32)\n",
        "\n",
        "        E = K.T @ F01 @ K\n",
        "        pts1_u = cv2.undistortPoints(pts1.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "        pts2_u = cv2.undistortPoints(pts2.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "\n",
        "        _, R01, t01, inl01 = cv2.recoverPose(\n",
        "            E,\n",
        "            pts1_u.reshape(-1, 1, 2),\n",
        "            pts2_u.reshape(-1, 1, 2),\n",
        "        )\n",
        "        inl01 = inl01.ravel().astype(bool)\n",
        "\n",
        "        if inl01.sum() < 50:\n",
        "            print(f\"[seed] pair ({i0},{j0}) rejected: inliers={inl01.sum()}\")\n",
        "            continue\n",
        "\n",
        "        x1_seed = pts1_u[inl01]\n",
        "        x2_seed = pts2_u[inl01]\n",
        "        b1 = np.column_stack([x1_seed, np.ones(len(x1_seed))])\n",
        "        b2 = (R01 @ np.column_stack([x2_seed, np.ones(len(x2_seed))]).T).T\n",
        "        b1 /= np.linalg.norm(b1, axis=1, keepdims=True)\n",
        "        b2 /= np.linalg.norm(b2, axis=1, keepdims=True)\n",
        "        ang = np.degrees(np.arccos(np.clip(np.sum(b1 * b2, axis=1), -1, 1)))\n",
        "        ang_med = np.median(ang)\n",
        "\n",
        "        if ang_med < min_parallax_deg:\n",
        "            print(f\"[seed] pair ({i0},{j0}) rejected: parallax={ang_med:.2f} deg\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[seed] using pair ({i0},{j0}), parallax={ang_med:.2f} deg, inliers={inl01.sum()}\")\n",
        "        return i0, j0, matches0, F01, R01, t01, inl01, pts1, pts2, pts1_u, pts2_u\n",
        "\n",
        "    i0, j0, matches0, F01 = good_pairs[0]\n",
        "    print(f\"[seed] fallback to first pair ({i0},{j0}) without parallax check\")\n",
        "    pts1 = np.array([frames[i0].kps[m.queryIdx].pt for m in matches0], np.float32)\n",
        "    pts2 = np.array([frames[j0].kps[m.trainIdx].pt for m in matches0], np.float32)\n",
        "    E = K.T @ F01 @ K\n",
        "    pts1_u = cv2.undistortPoints(pts1.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "    pts2_u = cv2.undistortPoints(pts2.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "    _, R01, t01, inl01 = cv2.recoverPose(\n",
        "        E,\n",
        "        pts1_u.reshape(-1, 1, 2),\n",
        "        pts2_u.reshape(-1, 1, 2),\n",
        "    )\n",
        "    inl01 = inl01.ravel().astype(bool)\n",
        "    return i0, j0, matches0, F01, R01, t01, inl01, pts1, pts2, pts1_u, pts2_u\n",
        "\n",
        "\n",
        "# Choose seed pair with decent parallax\n",
        "i0, j0, matches0, F01, R01, t01, inl01, pts1, pts2, pts1_u, pts2_u = \\\n",
        "    choose_seed_pair(good_pairs, K, frames, min_parallax_deg=1.0)\n",
        "\n",
        "# Camera poses, 3D points and observations initialization\n",
        "poses: Dict[int, Tuple[np.ndarray,np.ndarray]] = {}\n",
        "points3d: Dict[int, np.ndarray] = {}\n",
        "observations: Dict[int, List[Tuple[int, np.ndarray]]] = {}\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "obs_by_frame: Dict[int, List[Tuple[np.ndarray, int]]] = defaultdict(list)\n",
        "kp2pid_by_frame: Dict[int, Dict[int, int]] = defaultdict(dict)\n",
        "\n",
        "def add_observation(pid: int, frame_id: int, m_px: np.ndarray):\n",
        "    observations.setdefault(pid, []).append((frame_id, m_px))\n",
        "    obs_by_frame[frame_id].append((m_px, pid))\n",
        "\n",
        "\n",
        "poses[i0] = (np.zeros(3), np.zeros(3))\n",
        "rvec1, _ = cv2.Rodrigues(R01)\n",
        "poses[j0] = (rvec1.ravel(), t01.ravel())\n",
        "\n",
        "# Triangulate initial 3D points from first good pair\n",
        "x1n = pts1_u[inl01]\n",
        "x2n = pts2_u[inl01]\n",
        "P0 = np.hstack([np.eye(3), np.zeros((3,1))])\n",
        "P1 = np.hstack([R01, t01])\n",
        "X01 = triangulate_points(P0, P1, x1n, x2n)\n",
        "angle = parallax_angle(R01, t01, X01)\n",
        "\n",
        "\n",
        "# Filter and validate initial triangulated 3D points between first two frames\n",
        "SEED_REPROJ_THRESH = 5.0\n",
        "\n",
        "# Filter and validate initial triangulated 3D points between first two frames\n",
        "kept = 0\n",
        "# indices of inlier matches in the original matches0 list\n",
        "inlier_idx = np.where(inl01)[0]\n",
        "\n",
        "for j, X in enumerate(X01):\n",
        "    idx = inlier_idx[j]\n",
        "    m0  = matches0[idx]\n",
        "    kp_i = m0.queryIdx\n",
        "    kp_j = m0.trainIdx\n",
        "\n",
        "    z0 = (np.eye(3) @ X + np.zeros(3))[2]\n",
        "    z1 = (R01 @ X + t01.ravel())[2]\n",
        "    if z0 <= 0 or z1 <= 0:\n",
        "        continue\n",
        "\n",
        "    # Reprojection error sanity check for both views\n",
        "    pr0 = project_points(X[None,:], np.zeros(3), np.zeros(3), K)[0]\n",
        "    pr1 = project_points(X[None,:], cv2.Rodrigues(R01)[0].ravel(), t01.ravel(), K)[0]\n",
        "\n",
        "    if np.linalg.norm(pr0 - pts1[inl01][j]) < SEED_REPROJ_THRESH and \\\n",
        "       np.linalg.norm(pr1 - pts2[inl01][j]) < SEED_REPROJ_THRESH:\n",
        "\n",
        "        pid = len(points3d)\n",
        "        points3d[pid] = X\n",
        "\n",
        "        add_observation(pid, i0, pts1[inl01][j])\n",
        "        add_observation(pid, j0, pts2[inl01][j])\n",
        "\n",
        "        kp2pid_by_frame[i0][kp_i] = pid\n",
        "        kp2pid_by_frame[j0][kp_j] = pid\n",
        "\n",
        "        kept += 1\n",
        "\n",
        "print(f\"[seed] 3D points kept after reproj filter: {kept}\")\n",
        "\n",
        "if kept < 30:\n",
        "    print(f\"[seed] Fallback: using cheirality-only filter (was kept={kept})\")\n",
        "    points3d.clear()\n",
        "    observations.clear()\n",
        "    obs_by_frame.clear()\n",
        "    kp2pid_by_frame.clear()\n",
        "    kept = 0\n",
        "\n",
        "    for j, X in enumerate(X01):\n",
        "        idx = inlier_idx[j]\n",
        "        m0  = matches0[idx]\n",
        "        kp_i = m0.queryIdx\n",
        "        kp_j = m0.trainIdx\n",
        "\n",
        "        z0 = (np.eye(3) @ X + np.zeros(3))[2]\n",
        "        z1 = (R01 @ X + t01.ravel())[2]\n",
        "        if z0 <= 0 or z1 <= 0:\n",
        "            continue\n",
        "\n",
        "        pid = len(points3d)\n",
        "        points3d[pid] = X\n",
        "\n",
        "        add_observation(pid, i0, pts1[inl01][j])\n",
        "        add_observation(pid, j0, pts2[inl01][j])\n",
        "\n",
        "        kp2pid_by_frame[i0][kp_i] = pid\n",
        "        kp2pid_by_frame[j0][kp_j] = pid\n",
        "\n",
        "        kept += 1\n",
        "\n",
        "print(f\"[seed] total seed 3D points kept: {kept}\")\n",
        "\n",
        "if kept < 20:\n",
        "    print(\"[warn] Very few seed 3D points, reconstruction may be unstable\")\n",
        "\n",
        "MIN_PNP_POINTS = 12  # minimum number of 2D-3D correspondences for a reliable PnP\n",
        "# Begin incremental reconstruction using remaining good image pairs\n",
        "for (ia, ib, matches, F_ab) in good_pairs[1:]:\n",
        "    if ia not in poses:\n",
        "        continue\n",
        "\n",
        "    f_cur, f_nxt = frames[ia], frames[ib]\n",
        "    pts2d, pts3d_list = [], []\n",
        "\n",
        "    map_a = kp2pid_by_frame.get(ia, {})\n",
        "    for m in matches:\n",
        "        pid = map_a.get(m.queryIdx, None)\n",
        "        if pid is None:\n",
        "            continue\n",
        "        X = points3d.get(pid, None)\n",
        "        if X is None:\n",
        "            continue\n",
        "\n",
        "        pts3d_list.append(X)\n",
        "        pts2d.append(f_nxt.kps[m.trainIdx].pt)\n",
        "\n",
        "    if len(pts3d_list) < MIN_PNP_POINTS:\n",
        "        # Not enough constraints for a stable PnP -> skip this pair\n",
        "        continue\n",
        "\n",
        "    pts3d = np.asarray(pts3d_list, np.float32)\n",
        "    pts2d = np.asarray(pts2d, np.float32)\n",
        "\n",
        "    success, rvec, tvec, inl = cv2.solvePnPRansac(\n",
        "        pts3d, pts2d,\n",
        "        K, None,\n",
        "        iterationsCount=2000,\n",
        "        reprojectionError=2.5,\n",
        "        confidence=0.999\n",
        "    )\n",
        "\n",
        "    if (not success) or (inl is None) or (len(inl) < MIN_PNP_POINTS):\n",
        "        # PnP failed or too few inliers\n",
        "        continue\n",
        "\n",
        "    # Reject views with insufficient parallax for reliable triangulation\n",
        "    pts_i = np.array([f_cur.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "    pts_j = np.array([f_nxt.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "\n",
        "    pts_i_u = cv2.undistortPoints(pts_i.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "    pts_j_u = cv2.undistortPoints(pts_j.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "\n",
        "    R_est, _ = cv2.Rodrigues(rvec)\n",
        "    b1 = np.column_stack([pts_i_u, np.ones(len(pts_i_u))])\n",
        "    b2 = (R_est @ np.column_stack([pts_j_u, np.ones(len(pts_j_u))]).T).T\n",
        "    b1 /= np.linalg.norm(b1, axis=1, keepdims=True)\n",
        "    b2 /= np.linalg.norm(b2, axis=1, keepdims=True)\n",
        "    ang = np.degrees(np.arccos(np.clip(np.sum(b1 * b2, axis=1), -1, 1)))\n",
        "    if np.median(ang) < 3.0:\n",
        "        continue\n",
        "\n",
        "    # Pose assignment\n",
        "    poses.setdefault(ia, (np.zeros(3), np.zeros(3)))\n",
        "    poses[ib] = (rvec.ravel(), tvec.ravel())\n",
        "\n",
        "    # Triangulate new points\n",
        "    R_i, _ = cv2.Rodrigues(poses[ia][0]); t_i = poses[ia][1].reshape(3, 1)\n",
        "    R_j, _ = cv2.Rodrigues(poses[ib][0]); t_j = poses[ib][1].reshape(3, 1)\n",
        "    P_i = np.hstack([R_i, t_i])\n",
        "    P_j = np.hstack([R_j, t_j])\n",
        "\n",
        "    pts_i = np.array([f_cur.kps[m.queryIdx].pt for m in matches], np.float32)\n",
        "    pts_j = np.array([f_nxt.kps[m.trainIdx].pt for m in matches], np.float32)\n",
        "\n",
        "    pts_i_u = cv2.undistortPoints(pts_i.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "    pts_j_u = cv2.undistortPoints(pts_j.reshape(-1, 1, 2), K, None).reshape(-1, 2)\n",
        "\n",
        "    X_ij = triangulate_points(P_i, P_j, pts_i_u, pts_j_u)\n",
        "\n",
        "\n",
        "    # Validate and store newly triangulated points\n",
        "    for k, Xk in enumerate(X_ij):\n",
        "        z_i = (R_i @ Xk + t_i.ravel())[2]\n",
        "        z_j = (R_j @ Xk + t_j.ravel())[2]\n",
        "        if z_i <= 0 or z_j <= 0:\n",
        "            continue\n",
        "\n",
        "        pr_i = project_points(Xk[None, :], poses[ia][0], poses[ia][1], K)[0]\n",
        "        pr_j = project_points(Xk[None, :], poses[ib][0], poses[ib][1], K)[0]\n",
        "\n",
        "        if (np.linalg.norm(pr_i - pts_i[k]) >= 2.5) or (np.linalg.norm(pr_j - pts_j[k]) >= 2.5):\n",
        "            continue\n",
        "\n",
        "        # Link triangulated point to existing 3D point if keypoint in ia is already mapped\n",
        "        m = matches[k]\n",
        "        kp_i = m.queryIdx\n",
        "        kp_j = m.trainIdx\n",
        "\n",
        "        existing_pid = kp2pid_by_frame[ia].get(kp_i, None)\n",
        "\n",
        "        if existing_pid is not None:\n",
        "            # Add new observation for ib\n",
        "            add_observation(existing_pid, ib, pts_j[k])\n",
        "            kp2pid_by_frame[ib][kp_j] = existing_pid\n",
        "        else:\n",
        "            # Register a new 3D point and map both keypoints to it\n",
        "            pid = len(points3d)\n",
        "            points3d[pid] = Xk\n",
        "\n",
        "            add_observation(pid, ia, pts_i[k])\n",
        "            add_observation(pid, ib, pts_j[k])\n",
        "\n",
        "            kp2pid_by_frame[ia][kp_i] = pid\n",
        "            kp2pid_by_frame[ib][kp_j] = pid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "2TubjIJ882Lq"
      },
      "outputs": [],
      "source": [
        "# Accumulate all reprojection errors for each 3D point across all its observations\n",
        "all_errs = []\n",
        "track_err = {}\n",
        "\n",
        "# Iterate over all 3D points and their associated 2D observations\n",
        "for pid, obs in observations.items():\n",
        "    errs = []\n",
        "    for (fi, m_px) in obs:\n",
        "        if fi not in poses:\n",
        "            continue\n",
        "        rvec, tvec = poses[fi]\n",
        "\n",
        "        # Project the 3D point into the image using the current estimated camera pose\n",
        "        pr = project_points(points3d[pid][None,:], rvec, tvec, K)[0]\n",
        "        errs.append(float(np.linalg.norm(pr - m_px)))\n",
        "    if errs:\n",
        "        track_err[pid] = errs\n",
        "        all_errs.extend(errs)\n",
        "\n",
        "# Detect outliers using robust statistics\n",
        "if all_errs:\n",
        "    # Compute first and third quartile of reprojection errors\n",
        "    q1, q3 = np.percentile(all_errs, [25, 75])\n",
        "    iqr = max(q3 - q1, 1e-6)\n",
        "    thr = q3 + 2.0*iqr\n",
        "\n",
        "    # Remove outlier observations for each 3D point\n",
        "    for pid, errs in list(track_err.items()):\n",
        "        keep_obs = []\n",
        "        for (fi, m_px), e in zip(observations[pid], errs):\n",
        "            if e < thr:\n",
        "                keep_obs.append((fi, m_px))\n",
        "        if len(keep_obs) >= 2:\n",
        "            observations[pid] = keep_obs\n",
        "        else:\n",
        "            observations.pop(pid, None)\n",
        "            points3d.pop(pid, None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFDb4oniasgl",
        "outputId": "99c183a2-17da-405a-b1aa-593b628ddf94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pre-BA] kept obs after culling: 2919\n",
            "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
            "       0              1         1.5339e+03                                    7.97e+03    \n",
            "       1              2         1.5335e+03      3.61e-01       6.44e-02       3.78e-01    \n",
            "       2              3         1.5335e+03      1.03e-09       3.33e-06       3.34e-05    \n",
            "Both `ftol` and `xtol` termination conditions are satisfied.\n",
            "Function evaluations 3, initial cost 1.5339e+03, final cost 1.5335e+03, first-order optimality 3.34e-05.\n",
            "[BA intr] f 591.20->591.26, cx 369.50->369.49, cy 229.00->228.99\n",
            "[After intr-BA] f≈591.3 px, cx=369.5, cy=229.0\n",
            "[BA] total frames=16, total points=1047, total raw obs=3065\n",
            "[BA] frames selected for BA: 16 (base=0, opt=15)\n",
            "[BA] frames actually used in obs: 16\n",
            "[BA] initial intrinsics: f=591.26, cx=369.49, cy=228.99\n",
            "[BA] initial RMS reprojection error: 1.3598 px (subset)\n",
            "[BA] starting full mini-BA optimization...\n",
            "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
            "       0              1         2.2788e+03                                    4.96e+04    \n",
            "       1              8         1.3769e+03      9.02e+02       3.90e+01       2.74e+04    \n",
            "       2              9         1.2569e+03      1.20e+02       3.75e+01       1.85e+04    \n",
            "       3             11         1.1779e+03      7.91e+01       9.38e+00       7.59e+03    \n",
            "       4             13         1.1553e+03      2.26e+01       2.34e+00       7.19e+03    \n",
            "       5             15         1.1032e+03      5.21e+01       1.47e-01       5.08e+03    \n",
            "The maximum number of function evaluations is exceeded.\n",
            "Function evaluations 15, initial cost 2.2788e+03, final cost 1.1032e+03, first-order optimality 5.08e+03.\n",
            "[BA] optimization finished, status=0, nfev=15\n",
            "[BA] intrinsics refined: f:  591.26 -> 602.24, cx: 369.49 -> 368.59, cy: 228.99 -> 228.09\n",
            "[BA] final   RMS reprojection error: 0.8969 px (subset)\n",
            "[Refined intrinsics] f≈602.2 px, cx=368.6, cy=228.1\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from scipy.optimize import least_squares\n",
        "    SCIPY_OK = True\n",
        "except Exception:\n",
        "    SCIPY_OK = False\n",
        "\n",
        "def ba_refine_intrinsics_only(\n",
        "    observations, poses, points3d, f0, cx0, cy0, W, H,\n",
        "    max_obs_total=12000, verbose=True,\n",
        "):\n",
        "    if not SCIPY_OK:\n",
        "        if verbose: print(\"[BA intr] SciPy NA\")\n",
        "        return f0, cx0, cy0\n",
        "\n",
        "    # Use pre-cleaned obs if available; else fallback to raw\n",
        "    global clean_obs\n",
        "    triplets = []\n",
        "    seen = 0\n",
        "    for (pid, fi, m_px) in clean_obs if 'clean_obs' in globals() else []:\n",
        "        if pid in points3d and fi in poses:\n",
        "            triplets.append((pid, fi, m_px))\n",
        "            seen += 1\n",
        "            if seen >= max_obs_total:\n",
        "                break\n",
        "    if not triplets:\n",
        "        # fallback: raw, very small cap\n",
        "        for pid, obs in observations.items():\n",
        "            if pid not in points3d: continue\n",
        "            for (fi, m_px) in obs:\n",
        "                if fi not in poses: continue\n",
        "                triplets.append((pid, fi, np.asarray(m_px, np.float64)))\n",
        "                if len(triplets) >= min(4000, max_obs_total):\n",
        "                    break\n",
        "            if len(triplets) >= min(4000, max_obs_total):\n",
        "                break\n",
        "\n",
        "    if len(triplets) < 200:\n",
        "        if verbose: print(f\"[BA intr] too few obs: {len(triplets)}\")\n",
        "        return f0, cx0, cy0\n",
        "\n",
        "    # Group by camera for batch projection\n",
        "    by_cam = {}\n",
        "    for pid, fi, m in triplets:\n",
        "        by_cam.setdefault(int(fi), {\"X\":[], \"m\":[]}).update({})\n",
        "        by_cam[int(fi)][\"X\"].append(points3d[pid])\n",
        "        by_cam[int(fi)][\"m\"].append(m)\n",
        "\n",
        "    cam_ids = sorted(by_cam.keys())\n",
        "    R_list, t_list, X_batches, m_batches = [], [], [], []\n",
        "    for fid in cam_ids:\n",
        "        rvec, tvec = poses[fid]\n",
        "        R, _ = cv2.Rodrigues(np.asarray(rvec, np.float64).reshape(3,1))\n",
        "        R_list.append(R)\n",
        "        t_list.append(np.asarray(tvec, np.float64).reshape(3,))\n",
        "        X_batches.append(np.asarray(by_cam[fid][\"X\"], np.float64))\n",
        "        m_batches.append(np.asarray(by_cam[fid][\"m\"], np.float64))\n",
        "\n",
        "    f0 = float(f0); cx0 = float(cx0); cy0 = float(cy0)\n",
        "    maxWH = float(max(W,H))\n",
        "\n",
        "    def residuals(theta):\n",
        "        f, cx, cy = theta\n",
        "        res = []\n",
        "        for R, t, Xb, Mb in zip(R_list, t_list, X_batches, m_batches):\n",
        "            proj = pinhole_project_batch(f, cx, cy, R, t, Xb)\n",
        "            res.append((proj - Mb).ravel())\n",
        "        res = np.concatenate(res, axis=0)\n",
        "\n",
        "        # Weak priors\n",
        "        lam_f = 5e-6\n",
        "        lam_c = 5e-5\n",
        "        pri  = np.array([\n",
        "            lam_f * (f  - f0) / maxWH,\n",
        "            lam_c * (cx - cx0) / W,\n",
        "            lam_c * (cy - cy0) / H\n",
        "        ], dtype=np.float64)\n",
        "        return np.concatenate([res, pri], axis=0)\n",
        "\n",
        "    theta0 = np.array([f0, cx0, cy0], np.float64)\n",
        "    lb = np.array([0.55*maxWH, 0.25*W, 0.15*H], np.float64)\n",
        "    ub = np.array([2.20*maxWH, 0.75*W, 0.85*H], np.float64)\n",
        "\n",
        "    result = least_squares(\n",
        "        residuals, x0=theta0, bounds=(lb,ub),\n",
        "        loss=\"soft_l1\", f_scale=2.0,\n",
        "        max_nfev=12, verbose=2 if verbose else 0\n",
        "    )\n",
        "    f_opt, cx_opt, cy_opt = result.x\n",
        "    if verbose:\n",
        "        print(f\"[BA intr] f {f0:.2f}->{f_opt:.2f}, cx {cx0:.2f}->{cx_opt:.2f}, cy {cy0:.2f}->{cy_opt:.2f}\")\n",
        "    return float(f_opt), float(cx_opt), float(cy_opt)\n",
        "\n",
        "\n",
        "\n",
        "def ba_refine_f_cx_cy_full(\n",
        "    observations,\n",
        "    poses,\n",
        "    points3d,\n",
        "    f0,\n",
        "    cx0,\n",
        "    cy0,\n",
        "    W,\n",
        "    H,\n",
        "    max_frames_ba: int = 15,\n",
        "    max_points_ba: int = 800,\n",
        "    max_obs_total: int = 10000,\n",
        "    verbose: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Mini full bundle-adjustment:\n",
        "\n",
        "      - Optimizes intrinsics (f, cx, cy)\n",
        "      - Optimizes poses (rvec, tvec) for a subset of cameras\n",
        "      - Optimizes 3D points for a subset of tracks\n",
        "\n",
        "    All residuals are reprojection errors in pixels computed via cv2.projectPoints.\n",
        "    \"\"\"\n",
        "\n",
        "    if not SCIPY_OK:\n",
        "        print(\"[BA] SciPy not available, skipping BA\")\n",
        "        return float(f0), float(cx0), float(cy0)\n",
        "\n",
        "    if not poses or not points3d or not observations:\n",
        "        print(\"[BA] Empty poses/points/observations, skipping BA\")\n",
        "        return float(f0), float(cx0), float(cy0)\n",
        "\n",
        "    total_frames = len(poses)\n",
        "    total_points = len(points3d)\n",
        "    total_obs_raw = sum(len(v) for v in observations.values())\n",
        "    print(f\"[BA] total frames={total_frames}, total points={total_points}, total raw obs={total_obs_raw}\")\n",
        "\n",
        "    # Select subset of frames for BA\n",
        "    frame_ids = sorted(int(fi) for fi in poses.keys())\n",
        "    if not frame_ids:\n",
        "        print(\"[BA] No frame ids, skipping BA\")\n",
        "        return float(f0), float(cx0), float(cy0)\n",
        "\n",
        "    if len(frame_ids) > max_frames_ba:\n",
        "        step = max(1, len(frame_ids) // max_frames_ba)\n",
        "        frame_ids = frame_ids[::step]\n",
        "\n",
        "    frame_set = set(frame_ids)\n",
        "    base_fid = frame_ids[0]       # base camera: fixed pose\n",
        "    opt_frame_ids = [fid for fid in frame_ids if fid != base_fid]\n",
        "    cam_index = {fid: idx for idx, fid in enumerate(opt_frame_ids)}\n",
        "    n_cams_opt = len(opt_frame_ids)\n",
        "\n",
        "    print(f\"[BA] frames selected for BA: {len(frame_ids)} (base={base_fid}, opt={n_cams_opt})\")\n",
        "\n",
        "    # Build subset of points and observations\n",
        "    pt_ids      = []\n",
        "    X0_list     = []\n",
        "    obs_pt_idx  = []\n",
        "    obs_cam_idx = []\n",
        "    obs_meas    = []\n",
        "\n",
        "    pts_used = 0\n",
        "    obs_used = 0\n",
        "\n",
        "    for pid, X in points3d.items():\n",
        "        obs_full = observations.get(pid, [])\n",
        "        if not obs_full:\n",
        "            continue\n",
        "\n",
        "        # Take only obs from selected frames\n",
        "        obs_f = [(int(fi), m) for (fi, m) in obs_full if int(fi) in frame_set]\n",
        "        if len(obs_f) < 2:\n",
        "            continue\n",
        "\n",
        "        pt_idx = len(pt_ids)\n",
        "        pt_ids.append(pid)\n",
        "        X0_list.append(np.asarray(X, dtype=np.float64).reshape(3,))\n",
        "\n",
        "        for (fi, m_px) in obs_f:\n",
        "            if fi not in poses:\n",
        "                continue\n",
        "\n",
        "            # Determine camera index for this frame\n",
        "            if fi == base_fid:\n",
        "                ci = -1\n",
        "            else:\n",
        "                ci = cam_index.get(fi, -1)\n",
        "                if ci == -1:\n",
        "                    # This frame is not in the subset of cameras we optimize\n",
        "                    continue\n",
        "            obs_pt_idx.append(pt_idx)\n",
        "            obs_cam_idx.append(ci)\n",
        "            obs_meas.append(np.asarray(m_px, dtype=np.float64).reshape(2,))\n",
        "\n",
        "            obs_used += 1\n",
        "            if obs_used >= max_obs_total:\n",
        "                break\n",
        "\n",
        "        pts_used += 1\n",
        "        if pts_used >= max_points_ba or obs_used >= max_obs_total:\n",
        "            break\n",
        "\n",
        "    if obs_used < 60 or pts_used < 30 or len(obs_meas) < 40:\n",
        "        print(f\"[BA] Not enough obs/points for BA (points_used={pts_used}, obs_used={obs_used}), skip\")\n",
        "        return float(f0), float(cx0), float(cy0)\n",
        "\n",
        "    X0 = np.vstack(X0_list).astype(np.float64)\n",
        "    obs_meas    = np.vstack(obs_meas).astype(np.float64)\n",
        "    obs_pt_idx  = np.asarray(obs_pt_idx,  dtype=np.int32)\n",
        "    obs_cam_idx = np.asarray(obs_cam_idx, dtype=np.int32)\n",
        "\n",
        "    used_frames = sorted({base_fid} | {opt_frame_ids[ci] for ci in obs_cam_idx if ci >= 0})\n",
        "    print(f\"[BA] frames actually used in obs: {len(used_frames)}\")\n",
        "\n",
        "    # Initial extrinsics for opt cameras\n",
        "    rvecs0 = np.zeros((n_cams_opt, 3), dtype=np.float64)\n",
        "    tvecs0 = np.zeros((n_cams_opt, 3), dtype=np.float64)\n",
        "    for fid in opt_frame_ids:\n",
        "        if fid not in poses:\n",
        "            continue\n",
        "        rvec, tvec = poses[fid]\n",
        "        rvecs0[cam_index[fid]] = np.asarray(rvec, dtype=np.float64).reshape(3,)\n",
        "        tvecs0[cam_index[fid]] = np.asarray(tvec, dtype=np.float64).reshape(3,)\n",
        "\n",
        "    f0  = float(f0)\n",
        "    cx0 = float(cx0)\n",
        "    cy0 = float(cy0)\n",
        "    maxWH = float(max(W, H))\n",
        "\n",
        "    print(f\"[BA] initial intrinsics: f={f0:.2f}, cx={cx0:.2f}, cy={cy0:.2f}\")\n",
        "\n",
        "    def pack_params(f, cx, cy, rvecs, tvecs, X):\n",
        "        return np.concatenate(\n",
        "            [\n",
        "                np.array([f, cx, cy], dtype=np.float64),\n",
        "                rvecs.ravel(),\n",
        "                tvecs.ravel(),\n",
        "                X.ravel(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def unpack_params(theta):\n",
        "        theta = np.asarray(theta, dtype=np.float64).ravel()\n",
        "        f, cx, cy = theta[0], theta[1], theta[2]\n",
        "        off = 3\n",
        "\n",
        "        rvecs = rvecs0.copy()\n",
        "        tvecs = tvecs0.copy()\n",
        "\n",
        "        if n_cams_opt > 0:\n",
        "            rvecs = theta[off : off + 3 * n_cams_opt].reshape(n_cams_opt, 3)\n",
        "            off += 3 * n_cams_opt\n",
        "            tvecs = theta[off : off + 3 * n_cams_opt].reshape(n_cams_opt, 3)\n",
        "            off += 3 * n_cams_opt\n",
        "\n",
        "        X = theta[off:].reshape(X0.shape[0], 3)\n",
        "        return float(f), float(cx), float(cy), rvecs, tvecs, X\n",
        "\n",
        "    theta0 = pack_params(f0, cx0, cy0, rvecs0, tvecs0, X0)\n",
        "\n",
        "    lb = np.full_like(theta0, -np.inf, dtype=np.float64)\n",
        "    ub = np.full_like(theta0, +np.inf, dtype=np.float64)\n",
        "\n",
        "    f_lo = 0.5 * maxWH\n",
        "    f_hi = 2.5 * maxWH\n",
        "    cx_lo, cx_hi = 0.1 * W, 0.9 * W\n",
        "    cy_lo, cy_hi = 0.1 * H, 0.9 * H\n",
        "\n",
        "    lb[0], ub[0] = f_lo, f_hi\n",
        "    lb[1], ub[1] = cx_lo, cx_hi\n",
        "    lb[2], ub[2] = cy_lo, cy_hi\n",
        "\n",
        "    def compute_rms(f, cx, cy, rvecs, tvecs, X):\n",
        "        K_loc = np.array(\n",
        "            [\n",
        "                [f, 0.0, cx],\n",
        "                [0.0, f, cy],\n",
        "                [0.0, 0.0, 1.0],\n",
        "            ],\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        err2 = []\n",
        "        for k in range(obs_meas.shape[0]):\n",
        "            j = int(obs_pt_idx[k])\n",
        "            ci = int(obs_cam_idx[k])\n",
        "\n",
        "            if ci >= 0:\n",
        "                r = rvecs[ci]\n",
        "                t = tvecs[ci]\n",
        "            else:\n",
        "                r = np.zeros(3, dtype=np.float64)\n",
        "                t = np.zeros(3, dtype=np.float64)\n",
        "\n",
        "            Xj = X[j].reshape(1, 3).astype(np.float32)\n",
        "            r_ = r.reshape(3, 1).astype(np.float32)\n",
        "            t_ = t.reshape(3, 1).astype(np.float32)\n",
        "            proj, _ = cv2.projectPoints(Xj, r_, t_, K_loc, None)\n",
        "            proj = proj.reshape(2,)\n",
        "            diff = proj - obs_meas[k]\n",
        "            err2.append(float(diff.dot(diff)))\n",
        "        return math.sqrt(sum(err2) / len(err2))\n",
        "\n",
        "    rms0 = compute_rms(f0, cx0, cy0, rvecs0, tvecs0, X0)\n",
        "    print(f\"[BA] initial RMS reprojection error: {rms0:.4f} px (subset)\")\n",
        "\n",
        "\n",
        "\n",
        "    obs_idx_by_cam = {}\n",
        "    for k in range(obs_meas.shape[0]):\n",
        "        ci = int(obs_cam_idx[k])\n",
        "        obs_idx_by_cam.setdefault(ci, []).append(k)\n",
        "    for ci in list(obs_idx_by_cam.keys()):\n",
        "        obs_idx_by_cam[ci] = np.asarray(obs_idx_by_cam[ci], np.int32)\n",
        "\n",
        "\n",
        "    # Residuals for least_squares\n",
        "    def residuals(theta):\n",
        "        f, cx, cy, rvecs, tvecs, X = unpack_params(theta)\n",
        "\n",
        "        # Precompute rotation matrices for optimized cameras\n",
        "        Rs = np.zeros((n_cams_opt, 3, 3), np.float64)\n",
        "        for i in range(n_cams_opt):\n",
        "            R_i, _ = cv2.Rodrigues(rvecs[i].reshape(3,1))\n",
        "            Rs[i] = R_i\n",
        "\n",
        "        res_chunks = []\n",
        "\n",
        "        idx = obs_idx_by_cam.get(-1, None)\n",
        "        if idx is not None and idx.size:\n",
        "            j_idx = obs_pt_idx[idx]\n",
        "            Xb    = X[j_idx]\n",
        "            Rb    = np.eye(3, dtype=np.float64)\n",
        "            tb    = np.zeros(3, dtype=np.float64)\n",
        "            proj  = pinhole_project_batch(f, cx, cy, Rb, tb, Xb)\n",
        "            res_chunks.append((proj - obs_meas[idx]).ravel())\n",
        "\n",
        "        # Optimized cameras\n",
        "        for ci in range(n_cams_opt):\n",
        "            idx = obs_idx_by_cam.get(ci, None)\n",
        "            if idx is None or not idx.size:\n",
        "                continue\n",
        "            j_idx = obs_pt_idx[idx]\n",
        "            Xb    = X[j_idx]\n",
        "            proj  = pinhole_project_batch(f, cx, cy, Rs[ci], tvecs[ci], Xb)\n",
        "            res_chunks.append((proj - obs_meas[idx]).ravel())\n",
        "\n",
        "        res = np.concatenate(res_chunks, axis=0) if res_chunks else np.zeros(0, np.float64)\n",
        "\n",
        "        # Soft priors\n",
        "        lam_f    = 1e-5\n",
        "        lam_c    = 1e-4\n",
        "        lam_pose = 5e-5\n",
        "        lam_X    = 5e-6\n",
        "\n",
        "        pri = [\n",
        "            lam_f * (f  - f0)  / maxWH,\n",
        "            lam_c * (cx - cx0) / W,\n",
        "            lam_c * (cy - cy0) / H,\n",
        "        ]\n",
        "        pri.extend((lam_pose * (rvecs.ravel() - rvecs0.ravel())).tolist())\n",
        "        pri.extend((lam_pose * (tvecs.ravel() - tvecs0.ravel())).tolist())\n",
        "        pri.extend((lam_X    * (X.ravel()     - X0.ravel())).tolist())\n",
        "\n",
        "        return np.concatenate([res, np.asarray(pri, np.float64)], axis=0)\n",
        "\n",
        "\n",
        "    # Run optimizer\n",
        "    try:\n",
        "        print(\"[BA] starting full mini-BA optimization...\")\n",
        "        result = least_squares(\n",
        "            residuals,\n",
        "            x0=theta0,\n",
        "            bounds=(lb, ub),\n",
        "            loss=\"soft_l1\",\n",
        "            f_scale=2.0,\n",
        "            max_nfev=15,\n",
        "            verbose=2 if verbose else 0,\n",
        "        )\n",
        "        f_opt, cx_opt, cy_opt, rvecs_opt, tvecs_opt, X_opt = unpack_params(result.x)\n",
        "        rms1 = compute_rms(f_opt, cx_opt, cy_opt, rvecs_opt, tvecs_opt, X_opt)\n",
        "        print(f\"[BA] optimization finished, status={result.status}, nfev={result.nfev}\")\n",
        "        print(\n",
        "            f\"[BA] intrinsics refined: \"\n",
        "            f\"f:  {f0:.2f} -> {f_opt:.2f}, \"\n",
        "            f\"cx: {cx0:.2f} -> {cx_opt:.2f}, \"\n",
        "            f\"cy: {cy0:.2f} -> {cy_opt:.2f}\"\n",
        "        )\n",
        "        print(f\"[BA] final   RMS reprojection error: {rms1:.4f} px (subset)\")\n",
        "\n",
        "        # Optionally update poses and points back into global dicts\n",
        "        for fid in opt_frame_ids:\n",
        "            if fid not in poses:\n",
        "                continue\n",
        "            idx = cam_index[fid]\n",
        "            poses[fid] = (rvecs_opt[idx].copy(), tvecs_opt[idx].copy())\n",
        "\n",
        "        for local_idx, pid in enumerate(pt_ids):\n",
        "            points3d[pid] = X_opt[local_idx].copy()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[BA] least_squares failed with exception: {e}\")\n",
        "        f_opt, cx_opt, cy_opt = f0, cx0, cy0\n",
        "\n",
        "    return float(f_opt), float(cx_opt), float(cy_opt)\n",
        "\n",
        "\n",
        "\n",
        "# Pre-BA outlier culling and subsampling\n",
        "def _proj_err_px(K, rvec, tvec, X, m):\n",
        "    R, _ = cv2.Rodrigues(np.asarray(rvec, np.float64).reshape(3,1))\n",
        "    Xc = (R @ X.T + np.asarray(tvec, np.float64).reshape(3,1)).T\n",
        "    z  = Xc[:, 2:3]\n",
        "    good = z[:, 0] > 1e-6\n",
        "    u = Xc[:, :2] / np.clip(z, 1e-6, None)\n",
        "    u = u * K[0,0] + np.array([K[0,2], K[1,2]], dtype=np.float64)\n",
        "    err = np.linalg.norm(u - m, axis=1)\n",
        "    return err, good\n",
        "\n",
        "def build_clean_subset(observations, poses, points3d, K,\n",
        "                       per_frame_cap=800,\n",
        "                       err_thresh=3.0):\n",
        "    \"\"\"Return filtered observations: list of (pid, fi, m_px) only for inliers.\"\"\"\n",
        "    kept = []\n",
        "    for pid, obs in observations.items():\n",
        "        if pid not in points3d:\n",
        "            continue\n",
        "        X = np.asarray(points3d[pid], np.float64).reshape(1,3)\n",
        "        # Group obs by frame\n",
        "        byf = {}\n",
        "        for (fi, m) in obs:\n",
        "            if fi in poses:\n",
        "                byf.setdefault(int(fi), []).append(np.asarray(m, np.float64).reshape(2,))\n",
        "        for fi, ms in byf.items():\n",
        "            rvec, tvec = poses[fi]\n",
        "            M = np.stack(ms, axis=0)\n",
        "            Xrep = np.repeat(X, len(ms), axis=0)\n",
        "            err, good = _proj_err_px(K, rvec, tvec, Xrep, M)\n",
        "            idx = np.where((good) & (err < err_thresh))[0]\n",
        "            if idx.size:\n",
        "                if idx.size > per_frame_cap:\n",
        "                    idx = idx[:per_frame_cap]\n",
        "                for j in idx:\n",
        "                    kept.append((pid, fi, M[j]))\n",
        "    return kept\n",
        "\n",
        "clean_obs = build_clean_subset(observations, poses, points3d, K, per_frame_cap=600, err_thresh=3.0)\n",
        "print(f\"[Pre-BA] kept obs after culling: {len(clean_obs)}\")\n",
        "\n",
        "\n",
        "f_ba, cx_ba, cy_ba = ba_refine_intrinsics_only(\n",
        "    observations=observations,\n",
        "    poses=poses,\n",
        "    points3d=points3d,\n",
        "    f0=f_init,\n",
        "    cx0=cx,\n",
        "    cy0=cy,\n",
        "    W=W,\n",
        "    H=H,\n",
        "    max_obs_total=20000,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "fx_tmp = float(f_ba)\n",
        "fy_tmp = float(f_ba)\n",
        "cx_tmp = float(cx_ba)\n",
        "cy_tmp = float(cy_ba)\n",
        "\n",
        "K_tmp = np.array(\n",
        "    [\n",
        "        [fx_tmp, 0.0,   cx_tmp],\n",
        "        [0.0,    fy_tmp, cy_tmp],\n",
        "        [0.0,    0.0,   1.0],\n",
        "    ],\n",
        "    dtype=np.float64,\n",
        ")\n",
        "\n",
        "print(f\"[After intr-BA] f≈{fx_tmp:.1f} px, cx={cx_tmp:.1f}, cy={cy_tmp:.1f}\")\n",
        "\n",
        "f_refined, cx_ref, cy_ref = ba_refine_f_cx_cy_full(\n",
        "    observations=observations,\n",
        "    poses=poses,\n",
        "    points3d=points3d,\n",
        "    f0=f_ba,\n",
        "    cx0=cx_ba,\n",
        "    cy0=cy_ba,\n",
        "    W=W,\n",
        "    H=H,\n",
        "    max_frames_ba=20,\n",
        "    max_points_ba=1200,\n",
        "    max_obs_total=15000,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "# Post-processing: safety checks and final K\n",
        "f_floor = 0.6 * max(W, H)\n",
        "if (not np.isfinite(f_refined)) or (f_refined < f_floor):\n",
        "    print(f\"[BA] refined f={f_refined:.2f} is too small, fallback to >= {f_floor:.2f}\")\n",
        "    f_refined = max(f_ba, f_floor)\n",
        "\n",
        "cx_ref = float(np.clip(cx_ref, 0.3 * W, 0.7 * W))\n",
        "cy_ref = float(np.clip(cy_ref, 0.3 * H, 0.7 * H))\n",
        "\n",
        "K_ref = np.array(\n",
        "    [\n",
        "        [f_refined, 0.0,      cx_ref],\n",
        "        [0.0,       f_refined, cy_ref],\n",
        "        [0.0,       0.0,      1.0],\n",
        "    ],\n",
        "    dtype=np.float64,\n",
        ")\n",
        "\n",
        "K  = K_ref.copy()\n",
        "fx = float(K[0, 0]); fy = float(K[1, 1])\n",
        "cx = float(K[0, 2]); cy = float(K[1, 2])\n",
        "\n",
        "print(f\"[Refined intrinsics] f≈{fx:.1f} px, cx={cx:.1f}, cy={cy:.1f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLJtAPH-cxFK",
        "outputId": "0128256e-3032-4959-afaa-aaf61b715a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calibration.txt: /content/eth3d/training/einstein_1/calibration.txt True\n",
            "[GT compare] fx: est=602.2 gt=726.3  rel.err=17.08%\n",
            "[GT compare] fy: est=602.2 gt=726.3  rel.err=17.08%\n",
            "[GT compare] cx: est=368.6 gt=354.6  |Δ|=13.94px\n",
            "[GT compare] cy: est=228.1 gt=186.5  |Δ|=41.63px\n"
          ]
        }
      ],
      "source": [
        "out_dir = \"/content/out_sfm\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "np.save(os.path.join(out_dir, \"K.npy\"), K)\n",
        "\n",
        "\n",
        "K_est = np.load(\"/content/out_sfm/K.npy\")\n",
        "fx_e, fy_e, cx_e, cy_e = K_est[0,0], K_est[1,1], K_est[0,2], K_est[1,2]\n",
        "\n",
        "seq_dir = str(pathlib.Path(rgb_dir).parent)\n",
        "calib_path = os.path.join(seq_dir, \"calibration.txt\")\n",
        "print(\"calibration.txt:\", calib_path, os.path.exists(calib_path))\n",
        "\n",
        "fx_gt=fy_gt=cx_gt=cy_gt=None\n",
        "if os.path.exists(calib_path):\n",
        "    with open(calib_path, \"r\") as f:\n",
        "        txt = f.read()\n",
        "    nums = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", txt)\n",
        "    vals = list(map(float, nums))\n",
        "    for i in range(len(vals)-3):\n",
        "        fx_gt, fy_gt, cx_gt, cy_gt = vals[i:i+4]\n",
        "        if 50 < fx_gt < 20000 and 50 < fy_gt < 20000:\n",
        "            break\n",
        "\n",
        "    if fx_gt is not None:\n",
        "        rel_fx = abs(fx_e - fx_gt)/fx_gt\n",
        "        rel_fy = abs(fy_e - fy_gt)/fy_gt\n",
        "        dx = abs(cx_e - cx_gt); dy = abs(cy_e - cy_gt)\n",
        "\n",
        "        print(f\"[GT compare] fx: est={fx_e:.1f} gt={fx_gt:.1f}  rel.err={100*rel_fx:.2f}%\")\n",
        "        print(f\"[GT compare] fy: est={fy_e:.1f} gt={fy_gt:.1f}  rel.err={100*rel_fy:.2f}%\")\n",
        "        print(f\"[GT compare] cx: est={cx_e:.1f} gt={cx_gt:.1f}  |Δ|={dx:.2f}px\")\n",
        "        print(f\"[GT compare] cy: est={cy_e:.1f} gt={cy_gt:.1f}  |Δ|={dy:.2f}px\")\n",
        "    else:\n",
        "        print(\"Ground-truth intrinsics not parsed; check file format.\")\n",
        "else:\n",
        "    print(\"No ground truth file found for this sequence (test set or different layout).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72I2OP4kQUFm",
        "outputId": "11d0472d-76f1-4ebc-f301-59ec7ea4c566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chessboard-style mean (L2 divided by N): 0.06734798229153924\n",
            "Mean per-frame RMSE: 0.8894977616969626\n",
            "Global RMSE (px):    0.8969364065488314\n",
            "Worst 5 frames by RMSE: (11, {'chess_like': 0.07418023220359976, 'rmse': 1.0620992690205697, 'mae': 0.8538821339607239, 'N': 205}) (9, {'chess_like': 0.0713900885437266, 'rmse': 1.056476855322834, 'mae': 0.868816077709198, 'N': 219}) (15, {'chess_like': 0.0686077427854186, 'rmse': 1.0106551423116137, 'mae': 0.7742008566856384, 'N': 217}) (5, {'chess_like': 0.06911791510961861, 'rmse': 0.9676507743139702, 'mae': 0.7760979533195496, 'N': 196}) (13, {'chess_like': 0.08055879028005135, 'rmse': 0.9599687919411792, 'mae': 0.717512309551239, 'N': 142})\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "def reprojection_metrics_both(K, poses, points3d, observations, dist_opt=None):\n",
        "    \"\"\"\n",
        "    Compute two families of metrics:\n",
        "      1) 'Chessboard-style' score (as in many Zhang tutorials): L2 / N per frame, then averaged.\n",
        "      2) Proper reprojection errors:\n",
        "           - per-frame RMSE\n",
        "           - global RMSE (recommended)\n",
        "           - also global MAE and median for reference\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    summary : dict\n",
        "        {\n",
        "          \"mean_chess_like\": float,     # mean over frames of (L2 / N)\n",
        "          \"mean_rmse_frames\": float,    # mean over frames of per-frame RMSE\n",
        "          \"global_rmse\": float,         # sqrt( sum ||e||^2 / total_points )\n",
        "          \"global_mae\": float,          # mean ||e||\n",
        "          \"global_median\": float        # median ||e||\n",
        "        }\n",
        "    per_frame : dict[int -> dict]\n",
        "        Each entry: {\"chess_like\": ..., \"rmse\": ..., \"mae\": ..., \"N\": int}\n",
        "    \"\"\"\n",
        "\n",
        "    per_frame_X, per_frame_m = defaultdict(list), defaultdict(list)\n",
        "    for pid, obs_list in observations.items():\n",
        "        X = points3d.get(pid)\n",
        "        if X is None:\n",
        "            continue\n",
        "        X = np.asarray(X, np.float32).reshape(3,)\n",
        "        for (fi, m_px) in obs_list:\n",
        "            if fi in poses:\n",
        "                per_frame_X[int(fi)].append(X)\n",
        "                per_frame_m[int(fi)].append(np.asarray(m_px, np.float32).reshape(2,))\n",
        "\n",
        "    K32   = np.asarray(K, np.float32)\n",
        "    dist32 = None if dist_opt is None else np.asarray(dist_opt, np.float32)\n",
        "\n",
        "    # Per-frame metrics\n",
        "    per_frame = {}\n",
        "    chess_vals = []\n",
        "    rmse_vals  = []\n",
        "\n",
        "    all_errs = []   # accumulate per-point errors over all frames for global metrics\n",
        "\n",
        "    for fi in sorted(per_frame_X.keys()):\n",
        "        if fi not in poses:\n",
        "            continue\n",
        "\n",
        "        X3d = np.asarray(per_frame_X[fi], np.float32)\n",
        "        m2d = np.asarray(per_frame_m[fi], np.float32)\n",
        "        if X3d.size == 0:\n",
        "            continue\n",
        "\n",
        "        rvec, tvec = poses[fi]\n",
        "        r32 = np.asarray(rvec, np.float32).reshape(3,1)\n",
        "        t32 = np.asarray(tvec, np.float32).reshape(3,1)\n",
        "\n",
        "        proj, _ = cv2.projectPoints(X3d, r32, t32, K32, dist32)  # (N,1,2)\n",
        "        proj = proj.reshape(-1, 2)\n",
        "\n",
        "        diff = proj - m2d\n",
        "        N = len(diff)\n",
        "\n",
        "        # L2 / N\n",
        "        chess_like = cv2.norm(diff.reshape(-1,1,2), cv2.NORM_L2) / max(N, 1)\n",
        "\n",
        "        # 2) Proper errors\n",
        "        e = np.linalg.norm(diff, axis=1)          # per-point L2 in pixels\n",
        "        mae_i  = float(np.mean(e))                # mean absolute error (per frame, optional)\n",
        "        rmse_i = float(math.sqrt(np.mean(e**2)))  # RMSE per frame\n",
        "\n",
        "        per_frame[fi] = {\n",
        "            \"chess_like\": float(chess_like),\n",
        "            \"rmse\": rmse_i,\n",
        "            \"mae\": mae_i,\n",
        "            \"N\": int(N),\n",
        "        }\n",
        "        chess_vals.append(float(chess_like))\n",
        "        rmse_vals.append(rmse_i)\n",
        "        all_errs.append(e)\n",
        "\n",
        "    if all_errs:\n",
        "        all_errs = np.concatenate(all_errs, axis=0)\n",
        "        global_rmse   = float(math.sqrt(np.mean(all_errs**2)))\n",
        "        global_mae    = float(np.mean(all_errs))\n",
        "        global_median = float(np.median(all_errs))\n",
        "    else:\n",
        "        global_rmse = global_mae = global_median = float(\"nan\")\n",
        "\n",
        "    mean_chess_like  = float(np.mean(chess_vals)) if chess_vals else float(\"nan\")\n",
        "    mean_rmse_frames = float(np.mean(rmse_vals))  if rmse_vals  else float(\"nan\")\n",
        "\n",
        "    summary = {\n",
        "        \"mean_chess_like\":  mean_chess_like,   # matches the chess-style formula\n",
        "        \"mean_rmse_frames\": mean_rmse_frames,  # average of per-frame RMSE\n",
        "        \"global_rmse\":      global_rmse,       # preferred single number for reports\n",
        "        \"global_mae\":       global_mae,\n",
        "        \"global_median\":    global_median,\n",
        "    }\n",
        "    return summary, per_frame\n",
        "\n",
        "\n",
        "summary, per_frame = reprojection_metrics_both(K, poses, points3d, observations, dist_opt=None)\n",
        "print(\"Chessboard-style mean (L2 divided by N):\", summary[\"mean_chess_like\"])\n",
        "print(\"Mean per-frame RMSE:\",  summary[\"mean_rmse_frames\"])\n",
        "print(\"Global RMSE (px):   \",  summary[\"global_rmse\"])\n",
        "worst = sorted(per_frame.items(), key=lambda kv: kv[1][\"rmse\"], reverse=True)[:5]\n",
        "print(\"Worst 5 frames by RMSE:\", *worst)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
